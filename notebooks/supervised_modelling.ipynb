{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eae57e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_pickle(\"sl_final_for_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73f1997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns' , None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892ad85c",
   "metadata": {},
   "source": [
    "### ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41dab237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10633049, 47)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ce979a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'order_id', 'product_id', 'substitute_id', 'GMM_cluster_id',\n",
       "       'prod_price_usd', 'sub_price_usd', 'price_diff', 'price_ratio',\n",
       "       'prod_serving_quantity', 'sub_serving_quantity',\n",
       "       'serving_quantity_diff', 'serving_quantity_ratio',\n",
       "       'prod_product_popularity', 'sub_product_popularity',\n",
       "       'prod_global_reorder_prob', 'sub_global_reorder_prob',\n",
       "       'same_department', 'same_aisle', 'same_brand', 'same_final_category',\n",
       "       'nutriments_energy-kcal_100g_diff', 'nutriments_fat_100g_diff',\n",
       "       'nutriments_carbohydrates_100g_diff', 'nutriments_proteins_100g_diff',\n",
       "       'nutriments_sugars_100g_diff', 'nutriments_sodium_100g_diff',\n",
       "       'nutriments_salt_100g_diff', 'nutriments_saturated-fat_100g_diff',\n",
       "       'prod_ingredients_len', 'sub_ingredients_len', 'ingredients_len_diff',\n",
       "       'user_total_orders', 'user_reorder_rate',\n",
       "       'user_avg_days_between_orders', 'user_product_frequency_before',\n",
       "       'user_substitute_frequency_before', 'user_substitute_past_purchases',\n",
       "       'order_number', 'order_dow', 'order_hour_of_day',\n",
       "       'days_since_prior_order', 'basket_size', 'basket_unique_products',\n",
       "       'basket_total_price', 'basket_avg_price', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28e30a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>substitute_id</th>\n",
       "      <th>GMM_cluster_id</th>\n",
       "      <th>prod_price_usd</th>\n",
       "      <th>sub_price_usd</th>\n",
       "      <th>price_diff</th>\n",
       "      <th>price_ratio</th>\n",
       "      <th>prod_serving_quantity</th>\n",
       "      <th>sub_serving_quantity</th>\n",
       "      <th>serving_quantity_diff</th>\n",
       "      <th>serving_quantity_ratio</th>\n",
       "      <th>prod_product_popularity</th>\n",
       "      <th>sub_product_popularity</th>\n",
       "      <th>prod_global_reorder_prob</th>\n",
       "      <th>sub_global_reorder_prob</th>\n",
       "      <th>same_department</th>\n",
       "      <th>same_aisle</th>\n",
       "      <th>same_brand</th>\n",
       "      <th>same_final_category</th>\n",
       "      <th>nutriments_energy-kcal_100g_diff</th>\n",
       "      <th>nutriments_fat_100g_diff</th>\n",
       "      <th>nutriments_carbohydrates_100g_diff</th>\n",
       "      <th>nutriments_proteins_100g_diff</th>\n",
       "      <th>nutriments_sugars_100g_diff</th>\n",
       "      <th>nutriments_sodium_100g_diff</th>\n",
       "      <th>nutriments_salt_100g_diff</th>\n",
       "      <th>nutriments_saturated-fat_100g_diff</th>\n",
       "      <th>prod_ingredients_len</th>\n",
       "      <th>sub_ingredients_len</th>\n",
       "      <th>ingredients_len_diff</th>\n",
       "      <th>user_total_orders</th>\n",
       "      <th>user_reorder_rate</th>\n",
       "      <th>user_avg_days_between_orders</th>\n",
       "      <th>user_product_frequency_before</th>\n",
       "      <th>user_substitute_frequency_before</th>\n",
       "      <th>user_substitute_past_purchases</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>basket_size</th>\n",
       "      <th>basket_unique_products</th>\n",
       "      <th>basket_total_price</th>\n",
       "      <th>basket_avg_price</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6344</td>\n",
       "      <td>1506</td>\n",
       "      <td>40350</td>\n",
       "      <td>7228</td>\n",
       "      <td>0</td>\n",
       "      <td>6.79</td>\n",
       "      <td>2.99</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>0.440353</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>647</td>\n",
       "      <td>1896.0</td>\n",
       "      <td>0.336940</td>\n",
       "      <td>0.293249</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>4.430000</td>\n",
       "      <td>-3.330000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.081280</td>\n",
       "      <td>-2.703190</td>\n",
       "      <td>18.870001</td>\n",
       "      <td>274</td>\n",
       "      <td>254</td>\n",
       "      <td>-20</td>\n",
       "      <td>13</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>16.008696</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>49.00</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26938</td>\n",
       "      <td>2089</td>\n",
       "      <td>44663</td>\n",
       "      <td>45671</td>\n",
       "      <td>0</td>\n",
       "      <td>9.49</td>\n",
       "      <td>8.99</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.947313</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>717</td>\n",
       "      <td>519.0</td>\n",
       "      <td>0.359833</td>\n",
       "      <td>0.300578</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>7.799999</td>\n",
       "      <td>26.629999</td>\n",
       "      <td>-3.330000</td>\n",
       "      <td>22.200001</td>\n",
       "      <td>-0.809020</td>\n",
       "      <td>-2.022560</td>\n",
       "      <td>-1.670000</td>\n",
       "      <td>264</td>\n",
       "      <td>255</td>\n",
       "      <td>-9</td>\n",
       "      <td>16</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>16.155125</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>113.80</td>\n",
       "      <td>5.690000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26938</td>\n",
       "      <td>2089</td>\n",
       "      <td>19025</td>\n",
       "      <td>45671</td>\n",
       "      <td>0</td>\n",
       "      <td>11.49</td>\n",
       "      <td>8.99</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>0.782419</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>935</td>\n",
       "      <td>519.0</td>\n",
       "      <td>0.355080</td>\n",
       "      <td>0.300578</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>266.333336</td>\n",
       "      <td>19.466666</td>\n",
       "      <td>23.299999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.533334</td>\n",
       "      <td>-1.129553</td>\n",
       "      <td>-2.823893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>333</td>\n",
       "      <td>255</td>\n",
       "      <td>-78</td>\n",
       "      <td>16</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>16.155125</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>113.80</td>\n",
       "      <td>5.690000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26938</td>\n",
       "      <td>2089</td>\n",
       "      <td>19025</td>\n",
       "      <td>44663</td>\n",
       "      <td>0</td>\n",
       "      <td>11.49</td>\n",
       "      <td>9.49</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.825936</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>935</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.355080</td>\n",
       "      <td>0.359833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.333336</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>-3.330000</td>\n",
       "      <td>3.330000</td>\n",
       "      <td>-6.666667</td>\n",
       "      <td>-0.320533</td>\n",
       "      <td>-0.801333</td>\n",
       "      <td>1.670000</td>\n",
       "      <td>333</td>\n",
       "      <td>264</td>\n",
       "      <td>-69</td>\n",
       "      <td>16</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>16.155125</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>113.80</td>\n",
       "      <td>5.690000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14151</td>\n",
       "      <td>16086</td>\n",
       "      <td>16966</td>\n",
       "      <td>10916</td>\n",
       "      <td>0</td>\n",
       "      <td>2.49</td>\n",
       "      <td>7.49</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.008032</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>44</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.389474</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>-8.600000</td>\n",
       "      <td>-6.670000</td>\n",
       "      <td>39.570002</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>10.970000</td>\n",
       "      <td>656</td>\n",
       "      <td>180</td>\n",
       "      <td>-476</td>\n",
       "      <td>7</td>\n",
       "      <td>0.631206</td>\n",
       "      <td>18.219048</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>131.01</td>\n",
       "      <td>6.895263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  order_id  product_id  substitute_id  GMM_cluster_id  \\\n",
       "0     6344      1506       40350           7228               0   \n",
       "1    26938      2089       44663          45671               0   \n",
       "2    26938      2089       19025          45671               0   \n",
       "3    26938      2089       19025          44663               0   \n",
       "4    14151     16086       16966          10916               0   \n",
       "\n",
       "   prod_price_usd  sub_price_usd  price_diff  price_ratio  \\\n",
       "0            6.79           2.99        -3.8     0.440353   \n",
       "1            9.49           8.99        -0.5     0.947313   \n",
       "2           11.49           8.99        -2.5     0.782419   \n",
       "3           11.49           9.49        -2.0     0.825936   \n",
       "4            2.49           7.49         5.0     3.008032   \n",
       "\n",
       "   prod_serving_quantity  sub_serving_quantity  serving_quantity_diff  \\\n",
       "0                   30.0                  30.0                    0.0   \n",
       "1                   30.0                  30.0                    0.0   \n",
       "2                   30.0                  30.0                    0.0   \n",
       "3                   30.0                  30.0                    0.0   \n",
       "4                   30.0                   7.0                  -23.0   \n",
       "\n",
       "   serving_quantity_ratio  prod_product_popularity  sub_product_popularity  \\\n",
       "0                1.000000                      647                  1896.0   \n",
       "1                1.000000                      717                   519.0   \n",
       "2                1.000000                      935                   519.0   \n",
       "3                1.000000                      935                   717.0   \n",
       "4                0.233333                       44                   285.0   \n",
       "\n",
       "   prod_global_reorder_prob  sub_global_reorder_prob  same_department  \\\n",
       "0                  0.336940                 0.293249                1   \n",
       "1                  0.359833                 0.300578                1   \n",
       "2                  0.355080                 0.300578                1   \n",
       "3                  0.355080                 0.359833                1   \n",
       "4                  0.204545                 0.389474                1   \n",
       "\n",
       "   same_aisle  same_brand  same_final_category  \\\n",
       "0           1           0                    1   \n",
       "1           1           0                    1   \n",
       "2           1           0                    1   \n",
       "3           1           0                    1   \n",
       "4           1           0                    0   \n",
       "\n",
       "   nutriments_energy-kcal_100g_diff  nutriments_fat_100g_diff  \\\n",
       "0                       1240.000000                138.000000   \n",
       "1                        183.000000                  7.799999   \n",
       "2                        266.333336                 19.466666   \n",
       "3                         83.333336                 11.666667   \n",
       "4                         57.000000                 -8.600000   \n",
       "\n",
       "   nutriments_carbohydrates_100g_diff  nutriments_proteins_100g_diff  \\\n",
       "0                            4.430000                      -3.330000   \n",
       "1                           26.629999                      -3.330000   \n",
       "2                           23.299999                       0.000000   \n",
       "3                           -3.330000                       3.330000   \n",
       "4                           -6.670000                      39.570002   \n",
       "\n",
       "   nutriments_sugars_100g_diff  nutriments_sodium_100g_diff  \\\n",
       "0                     0.000000                    -1.081280   \n",
       "1                    22.200001                    -0.809020   \n",
       "2                    15.533334                    -1.129553   \n",
       "3                    -6.666667                    -0.320533   \n",
       "4                     1.600000                     2.100000   \n",
       "\n",
       "   nutriments_salt_100g_diff  nutriments_saturated-fat_100g_diff  \\\n",
       "0                  -2.703190                           18.870001   \n",
       "1                  -2.022560                           -1.670000   \n",
       "2                  -2.823893                            0.000000   \n",
       "3                  -0.801333                            1.670000   \n",
       "4                   5.250000                           10.970000   \n",
       "\n",
       "   prod_ingredients_len  sub_ingredients_len  ingredients_len_diff  \\\n",
       "0                   274                  254                   -20   \n",
       "1                   264                  255                    -9   \n",
       "2                   333                  255                   -78   \n",
       "3                   333                  264                   -69   \n",
       "4                   656                  180                  -476   \n",
       "\n",
       "   user_total_orders  user_reorder_rate  user_avg_days_between_orders  \\\n",
       "0                 13           0.587302                     16.008696   \n",
       "1                 16           0.588235                     16.155125   \n",
       "2                 16           0.588235                     16.155125   \n",
       "3                 16           0.588235                     16.155125   \n",
       "4                  7           0.631206                     18.219048   \n",
       "\n",
       "   user_product_frequency_before  user_substitute_frequency_before  \\\n",
       "0                              0                                 0   \n",
       "1                              2                                 0   \n",
       "2                              2                                 0   \n",
       "3                              2                                 2   \n",
       "4                              3                                 0   \n",
       "\n",
       "   user_substitute_past_purchases  order_number  order_dow  order_hour_of_day  \\\n",
       "0                               0            10          4                 14   \n",
       "1                               0            10          2                 18   \n",
       "2                               0            10          2                 18   \n",
       "3                               1            10          2                 18   \n",
       "4                               0             5          1                  7   \n",
       "\n",
       "   days_since_prior_order  basket_size  basket_unique_products  \\\n",
       "0                    12.0           10                      10   \n",
       "1                    17.0           20                      20   \n",
       "2                    17.0           20                      20   \n",
       "3                    17.0           20                      20   \n",
       "4                    18.0           19                      19   \n",
       "\n",
       "   basket_total_price  basket_avg_price  label  \n",
       "0               49.00          4.900000      1  \n",
       "1              113.80          5.690000      1  \n",
       "2              113.80          5.690000      1  \n",
       "3              113.80          5.690000      1  \n",
       "4              131.01          6.895263      1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f704f495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id', 'order_id', 'product_id', 'substitute_id', 'GMM_cluster_id']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in data.columns if 'id' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a5d5c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['user_id', 'order_id', 'product_id', 'substitute_id', 'GMM_cluster_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ec7e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b3410ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in df_idw.columns if x not in id_cols + [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a088ffe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10633049, 47), (10633049, 47))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, data.drop_duplicates(subset = id_cols).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25c5a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75d891e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, train_size = 0.7, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd83f2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7443134, 47), (3189915, 47))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "704b3037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4deb8c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classification_metrics(model_name, y_true, y_pred, y_proba=None):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1  = f1_score(y_true, y_pred, average=\"binary\")  # change to 'macro' if multi-class\n",
    "    print(f\"{model_name} - Accuracy: {acc:.4f}, F1: {f1:.4f}\", end=\"\")\n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            auc = roc_auc_score(y_true, y_proba)\n",
    "            print(f\", ROC-AUC: {auc:.4f}\")\n",
    "        except ValueError:\n",
    "            # e.g. if only one class present in y_true\n",
    "            print(\", ROC-AUC: NA (only one class in y_true)\")\n",
    "    else:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd122a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3491667/2747080809.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_key['pred_rf_class']  = y_pred_train\n",
      "/tmp/ipykernel_3491667/2747080809.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_key['pred_rf_class']   = y_pred_test\n",
      "/tmp/ipykernel_3491667/2747080809.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_key['pred_rf_proba']   = y_proba_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Accuracy: 0.8490, F1: 0.5501, ROC-AUC: 0.9350\n",
      "RF classifier done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3491667/2747080809.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_key['pred_lr_class'] = y_pred_train\n",
      "/tmp/ipykernel_3491667/2747080809.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_key['pred_lr_class']  = y_pred_test\n",
      "/tmp/ipykernel_3491667/2747080809.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_key['pred_lr_proba']  = y_proba_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression - Accuracy: 0.9008, F1: 0.6014, ROC-AUC: 0.9025\n",
      "Logistic regression done\n",
      "[LightGBM] [Info] Number of positive: 790655, number of negative: 6652479\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.241991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7028\n",
      "[LightGBM] [Info] Number of data points in the train set: 7443134, number of used features: 41\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3491667/2747080809.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_key['pred_lgbm_class'] = y_pred_train\n",
      "/tmp/ipykernel_3491667/2747080809.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_key['pred_lgbm_class']  = y_pred_test\n",
      "/tmp/ipykernel_3491667/2747080809.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_key['pred_lgbm_proba']  = y_proba_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM - Accuracy: 0.8759, F1: 0.6033, ROC-AUC: 0.9530\n",
      "LightGBM classifier done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3491667/2747080809.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_key['pred_cat_class'] = y_pred_train\n",
      "/tmp/ipykernel_3491667/2747080809.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_key['pred_cat_class']  = y_pred_test\n",
      "/tmp/ipykernel_3491667/2747080809.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_key['pred_cat_proba']  = y_proba_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost - Accuracy: 0.9398, F1: 0.6660, ROC-AUC: 0.9479\n",
      "CatBoost classifier done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Random Forest Classifier\n",
    "# -------------------------------------------------------------------\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    min_samples_split=1000,\n",
    "    min_samples_leaf=100,\n",
    "    max_features='sqrt',\n",
    "    bootstrap=True,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    class_weight='balanced_subsample'  # helps with class imbalance\n",
    ")\n",
    "\n",
    "rf_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_train = rf_clf.predict(X_train_scaled)\n",
    "y_pred_test  = rf_clf.predict(X_test_scaled)\n",
    "\n",
    "# probability of positive class (assumes binary 0/1)\n",
    "y_proba_test = rf_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "train_key['pred_rf_class']  = y_pred_train\n",
    "test_key['pred_rf_class']   = y_pred_test\n",
    "test_key['pred_rf_proba']   = y_proba_test\n",
    "\n",
    "print_classification_metrics(\"RandomForest\", y_test, y_pred_test, y_proba_test)\n",
    "print(\"RF classifier done\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Logistic Regression\n",
    "# -------------------------------------------------------------------\n",
    "log_reg = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=1.0,\n",
    "    solver='lbfgs',\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced'  # helps if target is imbalanced\n",
    ")\n",
    "\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_train = log_reg.predict(X_train_scaled)\n",
    "y_pred_test  = log_reg.predict(X_test_scaled)\n",
    "y_proba_test = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "train_key['pred_lr_class'] = y_pred_train\n",
    "test_key['pred_lr_class']  = y_pred_test\n",
    "test_key['pred_lr_proba']  = y_proba_test\n",
    "\n",
    "print_classification_metrics(\"LogisticRegression\", y_test, y_pred_test, y_proba_test)\n",
    "print(\"Logistic regression done\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# LightGBM Classifier\n",
    "# -------------------------------------------------------------------\n",
    "lgbm_clf = LGBMClassifier(\n",
    "    num_leaves=31,\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=500,\n",
    "    objective='binary',\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgbm_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_train = lgbm_clf.predict(X_train_scaled)\n",
    "y_pred_test  = lgbm_clf.predict(X_test_scaled)\n",
    "# LightGBM predict_proba\n",
    "y_proba_test = lgbm_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "train_key['pred_lgbm_class'] = y_pred_train\n",
    "test_key['pred_lgbm_class']  = y_pred_test\n",
    "test_key['pred_lgbm_proba']  = y_proba_test\n",
    "\n",
    "print_classification_metrics(\"LightGBM\", y_test, y_pred_test, y_proba_test)\n",
    "print(\"LightGBM classifier done\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# CatBoost Classifier\n",
    "# -------------------------------------------------------------------\n",
    "cat_clf = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    depth=6,\n",
    "    learning_rate=0.05,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    verbose=False,\n",
    "    random_seed=42,\n",
    "    class_weights=None  # or [w_for_class_0, w_for_class_1] if you want custom\n",
    ")\n",
    "\n",
    "cat_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_train = cat_clf.predict(X_train_scaled)\n",
    "y_pred_test  = cat_clf.predict(X_test_scaled).astype(int)  # CatBoost returns strings sometimes\n",
    "y_proba_test = cat_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "train_key['pred_cat_class'] = y_pred_train\n",
    "test_key['pred_cat_class']  = y_pred_test\n",
    "test_key['pred_cat_proba']  = y_proba_test\n",
    "\n",
    "print_classification_metrics(\"CatBoost\", y_test, y_pred_test, y_proba_test)\n",
    "print(\"CatBoost classifier done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dc726e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3491667/121785723.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_key['pred_rf_proba']   = rf_clf.predict_proba(X_train_scaled)[:, 1]\n",
      "/tmp/ipykernel_3491667/121785723.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_key['pred_lr_proba']  = log_reg.predict_proba(X_train_scaled)[:, 1]\n",
      "/tmp/ipykernel_3491667/121785723.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_key['pred_lgbm_proba']  = lgbm_clf.predict_proba(X_train_scaled)[:, 1]\n",
      "/tmp/ipykernel_3491667/121785723.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_key['pred_cat_proba']  = cat_clf.predict_proba(X_train_scaled)[:, 1]\n"
     ]
    }
   ],
   "source": [
    "train_key['pred_rf_proba']   = rf_clf.predict_proba(X_train_scaled)[:, 1]\n",
    "train_key['pred_lr_proba']  = log_reg.predict_proba(X_train_scaled)[:, 1]\n",
    "train_key['pred_lgbm_proba']  = lgbm_clf.predict_proba(X_train_scaled)[:, 1]\n",
    "train_key['pred_cat_proba']  = cat_clf.predict_proba(X_train_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b68b31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "op = (train_key[id_cols + ['pred_rf_proba', 'pred_lr_proba', 'pred_lgbm_proba', 'pred_cat_proba']],\n",
    "      test_key[id_cols + ['pred_rf_proba', 'pred_lr_proba', 'pred_lgbm_proba', 'pred_cat_proba']],\n",
    "      rf, lr, lgbm, cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "327e905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the dictionary to a binary file\n",
    "with open('model_op_ml.pkl', 'wb') as f:\n",
    "    pickle.dump(op, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ebdd19ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_op = pd.concat([\n",
    "    op[0],\n",
    "    op[1]\n",
    "          ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9e2b9319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'order_id', 'product_id', 'substitute_id', 'GMM_cluster_id',\n",
       "       'pred_rf_proba', 'pred_lr_proba', 'pred_lgbm_proba', 'pred_cat_proba'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "83afa100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'order_id', 'product_id', 'substitute_id', 'GMM_cluster_id',\n",
       "       'pred_rf_proba', 'pred_lr_proba', 'pred_lgbm_proba', 'pred_cat_proba'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op[1].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "49114bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_op.to_csv('../data/supervised_learning_predictions.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "85970a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>substitute_id</th>\n",
       "      <th>GMM_cluster_id</th>\n",
       "      <th>pred_rf_proba</th>\n",
       "      <th>pred_lr_proba</th>\n",
       "      <th>pred_lgbm_proba</th>\n",
       "      <th>pred_cat_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9335088</th>\n",
       "      <td>154565</td>\n",
       "      <td>1367172</td>\n",
       "      <td>2962</td>\n",
       "      <td>22089</td>\n",
       "      <td>63</td>\n",
       "      <td>0.511289</td>\n",
       "      <td>0.467650</td>\n",
       "      <td>0.322032</td>\n",
       "      <td>0.072946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9944958</th>\n",
       "      <td>151073</td>\n",
       "      <td>2857952</td>\n",
       "      <td>46045</td>\n",
       "      <td>27606</td>\n",
       "      <td>75</td>\n",
       "      <td>0.167330</td>\n",
       "      <td>0.251689</td>\n",
       "      <td>0.006941</td>\n",
       "      <td>0.001396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704721</th>\n",
       "      <td>150638</td>\n",
       "      <td>790551</td>\n",
       "      <td>45401</td>\n",
       "      <td>15468</td>\n",
       "      <td>16</td>\n",
       "      <td>0.124237</td>\n",
       "      <td>0.192894</td>\n",
       "      <td>0.063928</td>\n",
       "      <td>0.005806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492248</th>\n",
       "      <td>101433</td>\n",
       "      <td>1387828</td>\n",
       "      <td>33731</td>\n",
       "      <td>4799</td>\n",
       "      <td>15</td>\n",
       "      <td>0.759782</td>\n",
       "      <td>0.914044</td>\n",
       "      <td>0.921196</td>\n",
       "      <td>0.631459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4682778</th>\n",
       "      <td>164774</td>\n",
       "      <td>1971432</td>\n",
       "      <td>25890</td>\n",
       "      <td>30446</td>\n",
       "      <td>35</td>\n",
       "      <td>0.128468</td>\n",
       "      <td>0.181311</td>\n",
       "      <td>0.014037</td>\n",
       "      <td>0.001061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  order_id  product_id  substitute_id  GMM_cluster_id  \\\n",
       "9335088   154565   1367172        2962          22089              63   \n",
       "9944958   151073   2857952       46045          27606              75   \n",
       "2704721   150638    790551       45401          15468              16   \n",
       "2492248   101433   1387828       33731           4799              15   \n",
       "4682778   164774   1971432       25890          30446              35   \n",
       "\n",
       "         pred_rf_proba  pred_lr_proba  pred_lgbm_proba  pred_cat_proba  \n",
       "9335088       0.511289       0.467650         0.322032        0.072946  \n",
       "9944958       0.167330       0.251689         0.006941        0.001396  \n",
       "2704721       0.124237       0.192894         0.063928        0.005806  \n",
       "2492248       0.759782       0.914044         0.921196        0.631459  \n",
       "4682778       0.128468       0.181311         0.014037        0.001061  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_op.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03807416",
   "metadata": {},
   "source": [
    "## Optuna Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4d88a0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import optuna\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost.callback import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost.callback import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909c1789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe72e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-30 15:29:20,160] A new study created in memory with name: no-name-310dfd60-6865-4d22-99ec-00af1d2ca038\n",
      "[I 2025-11-30 15:30:42,261] Trial 0 finished with value: 0.1467475774758256 and parameters: {'learning_rate': 0.042098121232082494, 'n_estimators': 777, 'max_depth': 7, 'min_child_weight': 29.132577815217093, 'subsample': 0.6147968374729996, 'colsample_bytree': 0.485724487160419, 'colsample_bylevel': 0.9494368507946758, 'gamma': 3.520562738827442, 'reg_alpha': 0.14211414025518554, 'reg_lambda': 1.1299537693237707, 'max_bin': 416}. Best is trial 0 with value: 0.1467475774758256.\n",
      "[I 2025-11-30 15:31:28,110] Trial 1 finished with value: 0.15602432639815 and parameters: {'learning_rate': 0.04399109506258741, 'n_estimators': 689, 'max_depth': 4, 'min_child_weight': 6.865728559813745, 'subsample': 0.7376031405137949, 'colsample_bytree': 0.5091304974244799, 'colsample_bylevel': 0.9254974234816152, 'gamma': 5.46456337360755, 'reg_alpha': 0.592458647894528, 'reg_lambda': 10.322845756081211, 'max_bin': 299}. Best is trial 0 with value: 0.1467475774758256.\n",
      "[I 2025-11-30 15:31:59,498] Trial 2 finished with value: 0.15024309863278626 and parameters: {'learning_rate': 0.0993274104763657, 'n_estimators': 337, 'max_depth': 6, 'min_child_weight': 18.661593470230553, 'subsample': 0.7526868581624794, 'colsample_bytree': 0.5055403472138533, 'colsample_bylevel': 0.7425148769336459, 'gamma': 9.172758430969667, 'reg_alpha': 3.6723145874939886, 'reg_lambda': 0.1107683612276326, 'max_bin': 296}. Best is trial 0 with value: 0.1467475774758256.\n",
      "[I 2025-11-30 15:32:53,456] Trial 3 finished with value: 0.15248251414989836 and parameters: {'learning_rate': 0.05919460510975177, 'n_estimators': 693, 'max_depth': 5, 'min_child_weight': 45.894705275982915, 'subsample': 0.725467701316613, 'colsample_bytree': 0.3651546055842472, 'colsample_bylevel': 0.6184299483370925, 'gamma': 3.0128963835432665, 'reg_alpha': 0.13934510610869427, 'reg_lambda': 0.2780008122570305, 'max_bin': 320}. Best is trial 0 with value: 0.1467475774758256.\n",
      "[I 2025-11-30 15:33:43,209] Trial 4 finished with value: 0.15248334324756563 and parameters: {'learning_rate': 0.08925219585922123, 'n_estimators': 892, 'max_depth': 4, 'min_child_weight': 6.6635325066490445, 'subsample': 0.6038706390027667, 'colsample_bytree': 0.45062532540540234, 'colsample_bylevel': 0.7476296547944759, 'gamma': 8.911645346528061, 'reg_alpha': 5.062063124723636, 'reg_lambda': 3.7599500678623974, 'max_bin': 347}. Best is trial 0 with value: 0.1467475774758256.\n",
      "[I 2025-11-30 15:34:12,435] Trial 5 finished with value: 0.14913026061771 and parameters: {'learning_rate': 0.13160579835943778, 'n_estimators': 310, 'max_depth': 6, 'min_child_weight': 26.435444229563597, 'subsample': 0.6858793058161112, 'colsample_bytree': 0.48118191691200646, 'colsample_bylevel': 0.851597027057799, 'gamma': 6.952347013100504, 'reg_alpha': 4.75996279965895, 'reg_lambda': 0.23851910703216483, 'max_bin': 289}. Best is trial 0 with value: 0.1467475774758256.\n",
      "[I 2025-11-30 15:34:53,410] Trial 6 finished with value: 0.14880767932360914 and parameters: {'learning_rate': 0.06150945498144482, 'n_estimators': 393, 'max_depth': 7, 'min_child_weight': 14.476532906147316, 'subsample': 0.7386529478287844, 'colsample_bytree': 0.6130902947619212, 'colsample_bylevel': 0.6937129625920045, 'gamma': 4.3389579472039665, 'reg_alpha': 1.9903442335687895, 'reg_lambda': 0.127826826748361, 'max_bin': 130}. Best is trial 0 with value: 0.1467475774758256.\n",
      "[I 2025-11-30 15:35:31,513] Trial 7 finished with value: 0.1487928758715413 and parameters: {'learning_rate': 0.14716889172020353, 'n_estimators': 579, 'max_depth': 5, 'min_child_weight': 5.7731849953048275, 'subsample': 0.6654742298123172, 'colsample_bytree': 0.5853922720939813, 'colsample_bylevel': 0.7784406553929717, 'gamma': 6.75503470273056, 'reg_alpha': 8.893414995853494, 'reg_lambda': 0.40973889827859783, 'max_bin': 435}. Best is trial 0 with value: 0.1467475774758256.\n",
      "[I 2025-11-30 15:36:07,287] Trial 8 finished with value: 0.14915653617174632 and parameters: {'learning_rate': 0.12160845251051618, 'n_estimators': 461, 'max_depth': 5, 'min_child_weight': 12.580713688950318, 'subsample': 0.8598961336059461, 'colsample_bytree': 0.7454101338703711, 'colsample_bylevel': 0.7284575936619813, 'gamma': 2.8490715848654133, 'reg_alpha': 0.9213397497003383, 'reg_lambda': 1.811769290805607, 'max_bin': 360}. Best is trial 0 with value: 0.1467475774758256.\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    log_loss, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "# Keep your existing scaled data & keys:\n",
    "# X_train_scaled, X_test_scaled, y_train, y_test, train_key, test_key\n",
    "\n",
    "# Train/validation split (same pattern as your snippet)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train_scaled, y_train, test_size=0.3, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "n_classes = len(np.unique(y_train))\n",
    "is_binary = (n_classes == 2)\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        # ---- Objective & eval metric ----\n",
    "        \"objective\": \"binary:logistic\" if is_binary else \"multi:softprob\",\n",
    "        \"num_class\": None if is_binary else n_classes,\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"eval_metric\": \"logloss\" if is_binary else \"mlogloss\",\n",
    "\n",
    "        # ---- Learning rate & trees ----\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.03, 0.2, log=True),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 300, 900),\n",
    "\n",
    "        # ---- Tree complexity ----\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 3.0, 80.0, log=True),\n",
    "\n",
    "        # ---- Row & feature subsampling ----\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 0.9),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.3, 0.8),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.5, 1.0),\n",
    "\n",
    "        # ---- Regularization ----\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 1.0, 10.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.1, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.1, 20.0, log=True),\n",
    "\n",
    "        # ---- Histogram granularity ----\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 128, 512),\n",
    "\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        # tip: for heavy class imbalance (binary), consider\n",
    "        # \"scale_pos_weight\": (neg/pos)  you can add as a suggested_float/int\n",
    "    }\n",
    "\n",
    "    # Fit\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_tr, y_tr)\n",
    "\n",
    "    # Validate via log loss (works for binary & multiclass)\n",
    "    proba = model.predict_proba(X_val)\n",
    "    return log_loss(y_val, proba, labels=np.unique(y_train))\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n",
    "\n",
    "print(\"Best LogLoss:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n",
    "\n",
    "# Retrain on full training set with best params\n",
    "best_params = {\n",
    "    **study.best_params,\n",
    "    \"objective\": \"binary:logistic\" if is_binary else \"multi:softprob\",\n",
    "    \"num_class\": None if is_binary else n_classes,\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"eval_metric\": \"logloss\" if is_binary else \"mlogloss\",\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1,\n",
    "}\n",
    "\n",
    "# Save best params\n",
    "with open(f\"best_cls_params_{datetime.strftime(datetime.now(), '%Y%m%d%H%M')}_.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_params, f)\n",
    "\n",
    "best_model = XGBClassifier(**best_params)\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --- Predictions ---\n",
    "y_tr_pred = best_model.predict(X_train_scaled)\n",
    "y_te_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Probabilities (for AUC/thresholding)\n",
    "y_tr_proba = best_model.predict_proba(X_train_scaled)\n",
    "y_te_proba = best_model.predict_proba(X_test_scaled)\n",
    "\n",
    "# --- Metrics (train) ---\n",
    "print(\"\\n=== TRAIN METRICS ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_tr_pred))\n",
    "print(\"Precision (macro):\", precision_score(y_train, y_tr_pred, average=\"macro\", zero_division=0))\n",
    "print(\"Recall (macro):\", recall_score(y_train, y_tr_pred, average=\"macro\", zero_division=0))\n",
    "print(\"F1 (macro):\", f1_score(y_train, y_tr_pred, average=\"macro\", zero_division=0))\n",
    "if is_binary:\n",
    "    print(\"ROC-AUC:\", roc_auc_score(y_train, y_tr_proba[:, 1]))\n",
    "else:\n",
    "    print(\"ROC-AUC (OVR, macro):\", roc_auc_score(y_train, y_tr_proba, multi_class=\"ovr\", average=\"macro\"))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_train, y_tr_pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_train, y_tr_pred, zero_division=0))\n",
    "\n",
    "# --- Metrics (test) ---\n",
    "print(\"\\n=== TEST METRICS ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_te_pred))\n",
    "print(\"Precision (macro):\", precision_score(y_test, y_te_pred, average=\"macro\", zero_division=0))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_te_pred, average=\"macro\", zero_division=0))\n",
    "print(\"F1 (macro):\", f1_score(y_test, y_te_pred, average=\"macro\", zero_division=0))\n",
    "if is_binary:\n",
    "    print(\"ROC-AUC:\", roc_auc_score(y_test, y_te_proba[:, 1]))\n",
    "else:\n",
    "    print(\"ROC-AUC (OVR, macro):\", roc_auc_score(y_test, y_te_proba, multi_class=\"ovr\", average=\"macro\"))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_te_pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_te_pred, zero_division=0))\n",
    "\n",
    "# --- Attach predictions to keys ---\n",
    "# For consistency, use clear names:\n",
    "if is_binary:\n",
    "    # class (0/1) and probability of positive class\n",
    "    train_key['pred_class'] = y_tr_pred\n",
    "    train_key['pred_proba'] = y_tr_proba[:, 1]\n",
    "    test_key['pred_class'] = y_te_pred\n",
    "    test_key['pred_proba'] = y_te_proba[:, 1]\n",
    "else:\n",
    "    # class index and max probability\n",
    "    train_key['pred_class'] = y_tr_pred\n",
    "    train_key['pred_proba_max'] = y_tr_proba.max(axis=1)\n",
    "    test_key['pred_class'] = y_te_pred\n",
    "    test_key['pred_proba_max'] = y_te_proba.max(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c5a953ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## best hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ad6bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4709ebb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34be78a2",
   "metadata": {},
   "source": [
    "### FInal Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b18584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file = 'zzz'\n",
    "\n",
    "with open(file, 'rb') as f:\n",
    "    best_params = pickle.load(f)\n",
    "\n",
    "best_model = XGBRegressor(**best_params)\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "train_key['pred_xgb'] = best_model.predict(X_train_scaled)\n",
    "test_key['pred_xgb'] = best_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Train MSE:\", mean_squared_error(y_train, best_model.predict(X_train_scaled)))\n",
    "print(\"Train R2:\", r2_score(y_train, best_model.predict(X_train_scaled)))\n",
    "\n",
    "print(\"Test MSE:\", mean_squared_error(y_test, best_model.predict(X_test_scaled)))\n",
    "print(\"Test R2:\", r2_score(y_test, best_model.predict(X_test_scaled)))\n",
    "\n",
    "data_dict_xgb = (train_key,test_key, best_model, best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27bf82dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'learning_rate': 0.1999208810259104, 'n_estimators': 527, 'max_depth': 5, 'min_child_weight': 4.265252199053116,\n",
    "#           'subsample': 0.6414275366342287, 'colsample_bytree': 0.636700719035724, 'colsample_bylevel': 0.6884548644263487,\n",
    "#           'gamma': 7.4070170724996816, 'reg_alpha': 2.4894748515237164, 'reg_lambda': 0.4937774819547331, 'max_bin': 274}\n",
    "# best_model = XGBRegressor(**params)\n",
    "# best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "# train_key['pred_xgb'] = best_model.predict(X_train_scaled)\n",
    "# test_key['pred_xgb'] = best_model.predict(X_test_scaled)\n",
    "\n",
    "# print(\"Train MSE:\", mean_squared_error(y_train, best_model.predict(X_train_scaled)))\n",
    "# print(\"Train R2:\", r2_score(y_train, best_model.predict(X_train_scaled)))\n",
    "\n",
    "# print(\"Test MSE:\", mean_squared_error(y_test, best_model.predict(X_test_scaled)))\n",
    "# print(\"Test R2:\", r2_score(y_test, best_model.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d554ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a96aa59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_op_xgb = pd.concat([\n",
    "    data_dict_xgb[0],\n",
    "    data_dict_xgb[1]\n",
    "          ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad155023",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_op_xgb.rename({'pred_rf' : 'pred_xgb'}, axis = 1).to_csv('../data/preds_train_test_op_xgb_v2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5759d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7ee36f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a622deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b479a3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
