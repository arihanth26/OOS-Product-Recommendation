{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eae57e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_pickle(\"sl_final_for_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "440ca48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns' , None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892ad85c",
   "metadata": {},
   "source": [
    "### Train test split and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41dab237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10633049, 47)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2c525a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'order_id', 'product_id', 'substitute_id', 'GMM_cluster_id',\n",
       "       'prod_price_usd', 'sub_price_usd', 'price_diff', 'price_ratio',\n",
       "       'prod_serving_quantity', 'sub_serving_quantity',\n",
       "       'serving_quantity_diff', 'serving_quantity_ratio',\n",
       "       'prod_product_popularity', 'sub_product_popularity',\n",
       "       'prod_global_reorder_prob', 'sub_global_reorder_prob',\n",
       "       'same_department', 'same_aisle', 'same_brand', 'same_final_category',\n",
       "       'nutriments_energy-kcal_100g_diff', 'nutriments_fat_100g_diff',\n",
       "       'nutriments_carbohydrates_100g_diff', 'nutriments_proteins_100g_diff',\n",
       "       'nutriments_sugars_100g_diff', 'nutriments_sodium_100g_diff',\n",
       "       'nutriments_salt_100g_diff', 'nutriments_saturated-fat_100g_diff',\n",
       "       'prod_ingredients_len', 'sub_ingredients_len', 'ingredients_len_diff',\n",
       "       'user_total_orders', 'user_reorder_rate',\n",
       "       'user_avg_days_between_orders', 'user_product_frequency_before',\n",
       "       'user_substitute_frequency_before', 'user_substitute_past_purchases',\n",
       "       'order_number', 'order_dow', 'order_hour_of_day',\n",
       "       'days_since_prior_order', 'basket_size', 'basket_unique_products',\n",
       "       'basket_total_price', 'basket_avg_price', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a7df02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>substitute_id</th>\n",
       "      <th>GMM_cluster_id</th>\n",
       "      <th>prod_price_usd</th>\n",
       "      <th>sub_price_usd</th>\n",
       "      <th>price_diff</th>\n",
       "      <th>price_ratio</th>\n",
       "      <th>prod_serving_quantity</th>\n",
       "      <th>sub_serving_quantity</th>\n",
       "      <th>serving_quantity_diff</th>\n",
       "      <th>serving_quantity_ratio</th>\n",
       "      <th>prod_product_popularity</th>\n",
       "      <th>sub_product_popularity</th>\n",
       "      <th>prod_global_reorder_prob</th>\n",
       "      <th>sub_global_reorder_prob</th>\n",
       "      <th>same_department</th>\n",
       "      <th>same_aisle</th>\n",
       "      <th>same_brand</th>\n",
       "      <th>same_final_category</th>\n",
       "      <th>nutriments_energy-kcal_100g_diff</th>\n",
       "      <th>nutriments_fat_100g_diff</th>\n",
       "      <th>nutriments_carbohydrates_100g_diff</th>\n",
       "      <th>nutriments_proteins_100g_diff</th>\n",
       "      <th>nutriments_sugars_100g_diff</th>\n",
       "      <th>nutriments_sodium_100g_diff</th>\n",
       "      <th>nutriments_salt_100g_diff</th>\n",
       "      <th>nutriments_saturated-fat_100g_diff</th>\n",
       "      <th>prod_ingredients_len</th>\n",
       "      <th>sub_ingredients_len</th>\n",
       "      <th>ingredients_len_diff</th>\n",
       "      <th>user_total_orders</th>\n",
       "      <th>user_reorder_rate</th>\n",
       "      <th>user_avg_days_between_orders</th>\n",
       "      <th>user_product_frequency_before</th>\n",
       "      <th>user_substitute_frequency_before</th>\n",
       "      <th>user_substitute_past_purchases</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>basket_size</th>\n",
       "      <th>basket_unique_products</th>\n",
       "      <th>basket_total_price</th>\n",
       "      <th>basket_avg_price</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6344</td>\n",
       "      <td>1506</td>\n",
       "      <td>40350</td>\n",
       "      <td>7228</td>\n",
       "      <td>0</td>\n",
       "      <td>6.79</td>\n",
       "      <td>2.99</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>0.440353</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>647</td>\n",
       "      <td>1896.0</td>\n",
       "      <td>0.336940</td>\n",
       "      <td>0.293249</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>4.430000</td>\n",
       "      <td>-3.330000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.081280</td>\n",
       "      <td>-2.703190</td>\n",
       "      <td>18.870001</td>\n",
       "      <td>274</td>\n",
       "      <td>254</td>\n",
       "      <td>-20</td>\n",
       "      <td>13</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>16.008696</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>49.00</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26938</td>\n",
       "      <td>2089</td>\n",
       "      <td>44663</td>\n",
       "      <td>45671</td>\n",
       "      <td>0</td>\n",
       "      <td>9.49</td>\n",
       "      <td>8.99</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.947313</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>717</td>\n",
       "      <td>519.0</td>\n",
       "      <td>0.359833</td>\n",
       "      <td>0.300578</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>7.799999</td>\n",
       "      <td>26.629999</td>\n",
       "      <td>-3.330000</td>\n",
       "      <td>22.200001</td>\n",
       "      <td>-0.809020</td>\n",
       "      <td>-2.022560</td>\n",
       "      <td>-1.670000</td>\n",
       "      <td>264</td>\n",
       "      <td>255</td>\n",
       "      <td>-9</td>\n",
       "      <td>16</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>16.155125</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>113.80</td>\n",
       "      <td>5.690000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26938</td>\n",
       "      <td>2089</td>\n",
       "      <td>19025</td>\n",
       "      <td>45671</td>\n",
       "      <td>0</td>\n",
       "      <td>11.49</td>\n",
       "      <td>8.99</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>0.782419</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>935</td>\n",
       "      <td>519.0</td>\n",
       "      <td>0.355080</td>\n",
       "      <td>0.300578</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>266.333336</td>\n",
       "      <td>19.466666</td>\n",
       "      <td>23.299999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.533334</td>\n",
       "      <td>-1.129553</td>\n",
       "      <td>-2.823893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>333</td>\n",
       "      <td>255</td>\n",
       "      <td>-78</td>\n",
       "      <td>16</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>16.155125</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>113.80</td>\n",
       "      <td>5.690000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26938</td>\n",
       "      <td>2089</td>\n",
       "      <td>19025</td>\n",
       "      <td>44663</td>\n",
       "      <td>0</td>\n",
       "      <td>11.49</td>\n",
       "      <td>9.49</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.825936</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>935</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.355080</td>\n",
       "      <td>0.359833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.333336</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>-3.330000</td>\n",
       "      <td>3.330000</td>\n",
       "      <td>-6.666667</td>\n",
       "      <td>-0.320533</td>\n",
       "      <td>-0.801333</td>\n",
       "      <td>1.670000</td>\n",
       "      <td>333</td>\n",
       "      <td>264</td>\n",
       "      <td>-69</td>\n",
       "      <td>16</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>16.155125</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>113.80</td>\n",
       "      <td>5.690000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14151</td>\n",
       "      <td>16086</td>\n",
       "      <td>16966</td>\n",
       "      <td>10916</td>\n",
       "      <td>0</td>\n",
       "      <td>2.49</td>\n",
       "      <td>7.49</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.008032</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>44</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.389474</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>-8.600000</td>\n",
       "      <td>-6.670000</td>\n",
       "      <td>39.570002</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>10.970000</td>\n",
       "      <td>656</td>\n",
       "      <td>180</td>\n",
       "      <td>-476</td>\n",
       "      <td>7</td>\n",
       "      <td>0.631206</td>\n",
       "      <td>18.219048</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>131.01</td>\n",
       "      <td>6.895263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  order_id  product_id  substitute_id  GMM_cluster_id  \\\n",
       "0     6344      1506       40350           7228               0   \n",
       "1    26938      2089       44663          45671               0   \n",
       "2    26938      2089       19025          45671               0   \n",
       "3    26938      2089       19025          44663               0   \n",
       "4    14151     16086       16966          10916               0   \n",
       "\n",
       "   prod_price_usd  sub_price_usd  price_diff  price_ratio  \\\n",
       "0            6.79           2.99        -3.8     0.440353   \n",
       "1            9.49           8.99        -0.5     0.947313   \n",
       "2           11.49           8.99        -2.5     0.782419   \n",
       "3           11.49           9.49        -2.0     0.825936   \n",
       "4            2.49           7.49         5.0     3.008032   \n",
       "\n",
       "   prod_serving_quantity  sub_serving_quantity  serving_quantity_diff  \\\n",
       "0                   30.0                  30.0                    0.0   \n",
       "1                   30.0                  30.0                    0.0   \n",
       "2                   30.0                  30.0                    0.0   \n",
       "3                   30.0                  30.0                    0.0   \n",
       "4                   30.0                   7.0                  -23.0   \n",
       "\n",
       "   serving_quantity_ratio  prod_product_popularity  sub_product_popularity  \\\n",
       "0                1.000000                      647                  1896.0   \n",
       "1                1.000000                      717                   519.0   \n",
       "2                1.000000                      935                   519.0   \n",
       "3                1.000000                      935                   717.0   \n",
       "4                0.233333                       44                   285.0   \n",
       "\n",
       "   prod_global_reorder_prob  sub_global_reorder_prob  same_department  \\\n",
       "0                  0.336940                 0.293249                1   \n",
       "1                  0.359833                 0.300578                1   \n",
       "2                  0.355080                 0.300578                1   \n",
       "3                  0.355080                 0.359833                1   \n",
       "4                  0.204545                 0.389474                1   \n",
       "\n",
       "   same_aisle  same_brand  same_final_category  \\\n",
       "0           1           0                    1   \n",
       "1           1           0                    1   \n",
       "2           1           0                    1   \n",
       "3           1           0                    1   \n",
       "4           1           0                    0   \n",
       "\n",
       "   nutriments_energy-kcal_100g_diff  nutriments_fat_100g_diff  \\\n",
       "0                       1240.000000                138.000000   \n",
       "1                        183.000000                  7.799999   \n",
       "2                        266.333336                 19.466666   \n",
       "3                         83.333336                 11.666667   \n",
       "4                         57.000000                 -8.600000   \n",
       "\n",
       "   nutriments_carbohydrates_100g_diff  nutriments_proteins_100g_diff  \\\n",
       "0                            4.430000                      -3.330000   \n",
       "1                           26.629999                      -3.330000   \n",
       "2                           23.299999                       0.000000   \n",
       "3                           -3.330000                       3.330000   \n",
       "4                           -6.670000                      39.570002   \n",
       "\n",
       "   nutriments_sugars_100g_diff  nutriments_sodium_100g_diff  \\\n",
       "0                     0.000000                    -1.081280   \n",
       "1                    22.200001                    -0.809020   \n",
       "2                    15.533334                    -1.129553   \n",
       "3                    -6.666667                    -0.320533   \n",
       "4                     1.600000                     2.100000   \n",
       "\n",
       "   nutriments_salt_100g_diff  nutriments_saturated-fat_100g_diff  \\\n",
       "0                  -2.703190                           18.870001   \n",
       "1                  -2.022560                           -1.670000   \n",
       "2                  -2.823893                            0.000000   \n",
       "3                  -0.801333                            1.670000   \n",
       "4                   5.250000                           10.970000   \n",
       "\n",
       "   prod_ingredients_len  sub_ingredients_len  ingredients_len_diff  \\\n",
       "0                   274                  254                   -20   \n",
       "1                   264                  255                    -9   \n",
       "2                   333                  255                   -78   \n",
       "3                   333                  264                   -69   \n",
       "4                   656                  180                  -476   \n",
       "\n",
       "   user_total_orders  user_reorder_rate  user_avg_days_between_orders  \\\n",
       "0                 13           0.587302                     16.008696   \n",
       "1                 16           0.588235                     16.155125   \n",
       "2                 16           0.588235                     16.155125   \n",
       "3                 16           0.588235                     16.155125   \n",
       "4                  7           0.631206                     18.219048   \n",
       "\n",
       "   user_product_frequency_before  user_substitute_frequency_before  \\\n",
       "0                              0                                 0   \n",
       "1                              2                                 0   \n",
       "2                              2                                 0   \n",
       "3                              2                                 2   \n",
       "4                              3                                 0   \n",
       "\n",
       "   user_substitute_past_purchases  order_number  order_dow  order_hour_of_day  \\\n",
       "0                               0            10          4                 14   \n",
       "1                               0            10          2                 18   \n",
       "2                               0            10          2                 18   \n",
       "3                               1            10          2                 18   \n",
       "4                               0             5          1                  7   \n",
       "\n",
       "   days_since_prior_order  basket_size  basket_unique_products  \\\n",
       "0                    12.0           10                      10   \n",
       "1                    17.0           20                      20   \n",
       "2                    17.0           20                      20   \n",
       "3                    17.0           20                      20   \n",
       "4                    18.0           19                      19   \n",
       "\n",
       "   basket_total_price  basket_avg_price  label  \n",
       "0               49.00          4.900000      1  \n",
       "1              113.80          5.690000      1  \n",
       "2              113.80          5.690000      1  \n",
       "3              113.80          5.690000      1  \n",
       "4              131.01          6.895263      1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7e5fb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id', 'order_id', 'product_id', 'substitute_id', 'GMM_cluster_id']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in data.columns if 'id' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b58d7ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['user_id', 'order_id', 'product_id', 'substitute_id', 'GMM_cluster_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5389e5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c5c77bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in data.columns if x not in id_cols + [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7cdb4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10633049, 47), (10633049, 47))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, data.drop_duplicates(subset = id_cols).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67217793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c49b8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, train_size = 0.7, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee9c5c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7443134, 47), (3189915, 47))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85e6f5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling done\n"
     ]
    }
   ],
   "source": [
    "train_key = train[id_cols]\n",
    "test_key = test[id_cols]\n",
    "X_train = train.drop(columns=id_cols + [target])\n",
    "y_train = train[target] \n",
    "X_test = test.drop(columns=id_cols + [target]) \n",
    "y_test = test[target] \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train) \n",
    "X_test_scaled = scaler.transform(X_test) \n",
    "print('scaling done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f0ff67",
   "metadata": {},
   "source": [
    "### RF, LR, LightGBM,CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06eb8579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb23b3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classification_metrics(model_name, y_true, y_pred, y_proba=None):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1  = f1_score(y_true, y_pred, average=\"binary\")  # change to 'macro' if multi-class\n",
    "    print(f\"{model_name} - Accuracy: {acc:.4f}, F1: {f1:.4f}\", end=\"\")\n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            auc = roc_auc_score(y_true, y_proba)\n",
    "            print(f\", ROC-AUC: {auc:.4f}\")\n",
    "        except ValueError:\n",
    "            # e.g. if only one class present in y_true\n",
    "            print(\", ROC-AUC: NA (only one class in y_true)\")\n",
    "    else:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "29db2d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2537162/2747080809.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_key['pred_rf_class']  = y_pred_train\n",
      "/tmp/ipykernel_2537162/2747080809.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_key['pred_rf_class']   = y_pred_test\n",
      "/tmp/ipykernel_2537162/2747080809.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_key['pred_rf_proba']   = y_proba_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Accuracy: 0.8490, F1: 0.5501, ROC-AUC: 0.9350\n",
      "RF classifier done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2537162/2747080809.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_key['pred_lr_class'] = y_pred_train\n",
      "/tmp/ipykernel_2537162/2747080809.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_key['pred_lr_class']  = y_pred_test\n",
      "/tmp/ipykernel_2537162/2747080809.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_key['pred_lr_proba']  = y_proba_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression - Accuracy: 0.9008, F1: 0.6014, ROC-AUC: 0.9025\n",
      "Logistic regression done\n",
      "[LightGBM] [Info] Number of positive: 790655, number of negative: 6652479\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.254085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7028\n",
      "[LightGBM] [Info] Number of data points in the train set: 7443134, number of used features: 41\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2537162/2747080809.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_key['pred_lgbm_class'] = y_pred_train\n",
      "/tmp/ipykernel_2537162/2747080809.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_key['pred_lgbm_class']  = y_pred_test\n",
      "/tmp/ipykernel_2537162/2747080809.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_key['pred_lgbm_proba']  = y_proba_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM - Accuracy: 0.8759, F1: 0.6033, ROC-AUC: 0.9530\n",
      "LightGBM classifier done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2537162/2747080809.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_key['pred_cat_class'] = y_pred_train\n",
      "/tmp/ipykernel_2537162/2747080809.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_key['pred_cat_class']  = y_pred_test\n",
      "/tmp/ipykernel_2537162/2747080809.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_key['pred_cat_proba']  = y_proba_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost - Accuracy: 0.9398, F1: 0.6660, ROC-AUC: 0.9479\n",
      "CatBoost classifier done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Random Forest Classifier\n",
    "# -------------------------------------------------------------------\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    min_samples_split=1000,\n",
    "    min_samples_leaf=100,\n",
    "    max_features='sqrt',\n",
    "    bootstrap=True,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    class_weight='balanced_subsample'  # helps with class imbalance\n",
    ")\n",
    "\n",
    "rf_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_train = rf_clf.predict(X_train_scaled)\n",
    "y_pred_test  = rf_clf.predict(X_test_scaled)\n",
    "\n",
    "# probability of positive class (assumes binary 0/1)\n",
    "y_proba_test = rf_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "train_key['pred_rf_class']  = y_pred_train\n",
    "test_key['pred_rf_class']   = y_pred_test\n",
    "test_key['pred_rf_proba']   = y_proba_test\n",
    "\n",
    "print_classification_metrics(\"RandomForest\", y_test, y_pred_test, y_proba_test)\n",
    "print(\"RF classifier done\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Logistic Regression\n",
    "# -------------------------------------------------------------------\n",
    "log_reg = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=1.0,\n",
    "    solver='lbfgs',\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced'  # helps if target is imbalanced\n",
    ")\n",
    "\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_train = log_reg.predict(X_train_scaled)\n",
    "y_pred_test  = log_reg.predict(X_test_scaled)\n",
    "y_proba_test = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "train_key['pred_lr_class'] = y_pred_train\n",
    "test_key['pred_lr_class']  = y_pred_test\n",
    "test_key['pred_lr_proba']  = y_proba_test\n",
    "\n",
    "print_classification_metrics(\"LogisticRegression\", y_test, y_pred_test, y_proba_test)\n",
    "print(\"Logistic regression done\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# LightGBM Classifier\n",
    "# -------------------------------------------------------------------\n",
    "lgbm_clf = LGBMClassifier(\n",
    "    num_leaves=31,\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=500,\n",
    "    objective='binary',\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgbm_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_train = lgbm_clf.predict(X_train_scaled)\n",
    "y_pred_test  = lgbm_clf.predict(X_test_scaled)\n",
    "# LightGBM predict_proba\n",
    "y_proba_test = lgbm_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "train_key['pred_lgbm_class'] = y_pred_train\n",
    "test_key['pred_lgbm_class']  = y_pred_test\n",
    "test_key['pred_lgbm_proba']  = y_proba_test\n",
    "\n",
    "print_classification_metrics(\"LightGBM\", y_test, y_pred_test, y_proba_test)\n",
    "print(\"LightGBM classifier done\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# CatBoost Classifier\n",
    "# -------------------------------------------------------------------\n",
    "cat_clf = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    depth=6,\n",
    "    learning_rate=0.05,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    verbose=False,\n",
    "    random_seed=42,\n",
    "    class_weights=None  # or [w_for_class_0, w_for_class_1] if you want custom\n",
    ")\n",
    "\n",
    "cat_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_train = cat_clf.predict(X_train_scaled)\n",
    "y_pred_test  = cat_clf.predict(X_test_scaled).astype(int)  # CatBoost returns strings sometimes\n",
    "y_proba_test = cat_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "train_key['pred_cat_class'] = y_pred_train\n",
    "test_key['pred_cat_class']  = y_pred_test\n",
    "test_key['pred_cat_proba']  = y_proba_test\n",
    "\n",
    "print_classification_metrics(\"CatBoost\", y_test, y_pred_test, y_proba_test)\n",
    "print(\"CatBoost classifier done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae68cdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2537162/121785723.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_key['pred_rf_proba']   = rf_clf.predict_proba(X_train_scaled)[:, 1]\n",
      "/tmp/ipykernel_2537162/121785723.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_key['pred_lr_proba']  = log_reg.predict_proba(X_train_scaled)[:, 1]\n",
      "/tmp/ipykernel_2537162/121785723.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_key['pred_lgbm_proba']  = lgbm_clf.predict_proba(X_train_scaled)[:, 1]\n",
      "/tmp/ipykernel_2537162/121785723.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_key['pred_cat_proba']  = cat_clf.predict_proba(X_train_scaled)[:, 1]\n"
     ]
    }
   ],
   "source": [
    "train_key['pred_rf_proba']   = rf_clf.predict_proba(X_train_scaled)[:, 1]\n",
    "train_key['pred_lr_proba']  = log_reg.predict_proba(X_train_scaled)[:, 1]\n",
    "train_key['pred_lgbm_proba']  = lgbm_clf.predict_proba(X_train_scaled)[:, 1]\n",
    "train_key['pred_cat_proba']  = cat_clf.predict_proba(X_train_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dda0fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "op = (train_key[id_cols + ['pred_rf_proba', 'pred_lr_proba', 'pred_lgbm_proba', 'pred_cat_proba']],\n",
    "      test_key[id_cols + ['pred_rf_proba', 'pred_lr_proba', 'pred_lgbm_proba', 'pred_cat_proba']],\n",
    "      rf_clf, log_reg, lgbm_clf, cat_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "327e905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the dictionary to a binary file\n",
    "with open('model_op_ml.pkl', 'wb') as f:\n",
    "    pickle.dump(op, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ebdd19ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_op = pd.concat([\n",
    "    op[0],\n",
    "    op[1]\n",
    "          ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ce0015f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'order_id', 'product_id', 'substitute_id', 'GMM_cluster_id',\n",
       "       'pred_rf_proba', 'pred_lr_proba', 'pred_lgbm_proba', 'pred_cat_proba'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8420e1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'order_id', 'product_id', 'substitute_id', 'GMM_cluster_id',\n",
       "       'pred_rf_proba', 'pred_lr_proba', 'pred_lgbm_proba', 'pred_cat_proba'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op[1].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "49114bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_op.to_csv('../data/supervised_learning_predictions.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7c05aa11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>substitute_id</th>\n",
       "      <th>GMM_cluster_id</th>\n",
       "      <th>pred_rf_proba</th>\n",
       "      <th>pred_lr_proba</th>\n",
       "      <th>pred_lgbm_proba</th>\n",
       "      <th>pred_cat_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9335088</th>\n",
       "      <td>154565</td>\n",
       "      <td>1367172</td>\n",
       "      <td>2962</td>\n",
       "      <td>22089</td>\n",
       "      <td>63</td>\n",
       "      <td>0.511289</td>\n",
       "      <td>0.467650</td>\n",
       "      <td>0.322032</td>\n",
       "      <td>0.072946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9944958</th>\n",
       "      <td>151073</td>\n",
       "      <td>2857952</td>\n",
       "      <td>46045</td>\n",
       "      <td>27606</td>\n",
       "      <td>75</td>\n",
       "      <td>0.167330</td>\n",
       "      <td>0.251689</td>\n",
       "      <td>0.006941</td>\n",
       "      <td>0.001396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704721</th>\n",
       "      <td>150638</td>\n",
       "      <td>790551</td>\n",
       "      <td>45401</td>\n",
       "      <td>15468</td>\n",
       "      <td>16</td>\n",
       "      <td>0.124237</td>\n",
       "      <td>0.192894</td>\n",
       "      <td>0.063928</td>\n",
       "      <td>0.005806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492248</th>\n",
       "      <td>101433</td>\n",
       "      <td>1387828</td>\n",
       "      <td>33731</td>\n",
       "      <td>4799</td>\n",
       "      <td>15</td>\n",
       "      <td>0.759782</td>\n",
       "      <td>0.914044</td>\n",
       "      <td>0.921196</td>\n",
       "      <td>0.631459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4682778</th>\n",
       "      <td>164774</td>\n",
       "      <td>1971432</td>\n",
       "      <td>25890</td>\n",
       "      <td>30446</td>\n",
       "      <td>35</td>\n",
       "      <td>0.128468</td>\n",
       "      <td>0.181311</td>\n",
       "      <td>0.014037</td>\n",
       "      <td>0.001061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  order_id  product_id  substitute_id  GMM_cluster_id  \\\n",
       "9335088   154565   1367172        2962          22089              63   \n",
       "9944958   151073   2857952       46045          27606              75   \n",
       "2704721   150638    790551       45401          15468              16   \n",
       "2492248   101433   1387828       33731           4799              15   \n",
       "4682778   164774   1971432       25890          30446              35   \n",
       "\n",
       "         pred_rf_proba  pred_lr_proba  pred_lgbm_proba  pred_cat_proba  \n",
       "9335088       0.511289       0.467650         0.322032        0.072946  \n",
       "9944958       0.167330       0.251689         0.006941        0.001396  \n",
       "2704721       0.124237       0.192894         0.063928        0.005806  \n",
       "2492248       0.759782       0.914044         0.921196        0.631459  \n",
       "4682778       0.128468       0.181311         0.014037        0.001061  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_op.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03807416",
   "metadata": {},
   "source": [
    "### XGB - Optuna Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d88a0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    log_loss, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "from datetime import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21b8c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-30 15:29:20,160] A new study created in memory with name: no-name-310dfd60-6865-4d22-99ec-00af1d2ca038\n",
      "[I 2025-11-30 15:30:42,261] Trial 0 finished with value: 0.1467475774758256 and parameters: {'learning_rate': 0.042098121232082494, 'n_estimators': 777, 'max_depth': 7, 'min_child_weight': 29.132577815217093, 'subsample': 0.6147968374729996, 'colsample_bytree': 0.485724487160419, 'colsample_bylevel': 0.9494368507946758, 'gamma': 3.520562738827442, 'reg_alpha': 0.14211414025518554, 'reg_lambda': 1.1299537693237707, 'max_bin': 416}. Best is trial 0 with value: 0.1467475774758256.\n",
      "[I 2025-11-30 15:31:28,110] Trial 1 finished with value: 0.15602432639815 and parameters: {'learning_rate': 0.04399109506258741, 'n_estimators': 689, 'max_depth': 4, 'min_child_weight': 6.865728559813745, 'subsample': 0.7376031405137949, 'colsample_bytree': 0.5091304974244799, 'colsample_bylevel': 0.9254974234816152, 'gamma': 5.46456337360755, 'reg_alpha': 0.592458647894528, 'reg_lambda': 10.322845756081211, 'max_bin': 299}. Best is trial 0 with value: 0.1467475774758256.\n",
      "[I 2025-11-30 15:31:59,498] Trial 2 finished with value: 0.15024309863278626 and parameters: {'learning_rate': 0.0993274104763657, 'n_estimators': 337, 'max_depth': 6, 'min_child_weight': 18.661593470230553, 'subsample': 0.7526868581624794, 'colsample_bytree': 0.5055403472138533, 'colsample_bylevel': 0.7425148769336459, 'gamma': 9.172758430969667, 'reg_alpha': 3.6723145874939886, 'reg_lambda': 0.1107683612276326, 'max_bin': 296}. Best is trial 0 with value: 0.1467475774758256.\n",
      "[I 2025-11-30 15:32:53,456] Trial 3 finished with value: 0.15248251414989836 and parameters: {'learning_rate': 0.05919460510975177, 'n_estimators': 693, 'max_depth': 5, 'min_child_weight': 45.894705275982915, 'subsample': 0.725467701316613, 'colsample_bytree': 0.3651546055842472, 'colsample_bylevel': 0.6184299483370925, 'gamma': 3.0128963835432665, 'reg_alpha': 0.13934510610869427, 'reg_lambda': 0.2780008122570305, 'max_bin': 320}. Best is trial 0 with value: 0.1467475774758256.\n",
      "[I 2025-11-30 15:33:43,209] Trial 4 finished with value: 0.15248334324756563 and parameters: {'learning_rate': 0.08925219585922123, 'n_estimators': 892, 'max_depth': 4, 'min_child_weight': 6.6635325066490445, 'subsample': 0.6038706390027667, 'colsample_bytree': 0.45062532540540234, 'colsample_bylevel': 0.7476296547944759, 'gamma': 8.911645346528061, 'reg_alpha': 5.062063124723636, 'reg_lambda': 3.7599500678623974, 'max_bin': 347}. Best is trial 0 with value: 0.1467475774758256.\n",
      "[I 2025-11-30 15:34:12,435] Trial 5 finished with value: 0.14913026061771 and parameters: {'learning_rate': 0.13160579835943778, 'n_estimators': 310, 'max_depth': 6, 'min_child_weight': 26.435444229563597, 'subsample': 0.6858793058161112, 'colsample_bytree': 0.48118191691200646, 'colsample_bylevel': 0.851597027057799, 'gamma': 6.952347013100504, 'reg_alpha': 4.75996279965895, 'reg_lambda': 0.23851910703216483, 'max_bin': 289}. Best is trial 0 with value: 0.1467475774758256.\n",
      "[I 2025-11-30 15:34:53,410] Trial 6 finished with value: 0.14880767932360914 and parameters: {'learning_rate': 0.06150945498144482, 'n_estimators': 393, 'max_depth': 7, 'min_child_weight': 14.476532906147316, 'subsample': 0.7386529478287844, 'colsample_bytree': 0.6130902947619212, 'colsample_bylevel': 0.6937129625920045, 'gamma': 4.3389579472039665, 'reg_alpha': 1.9903442335687895, 'reg_lambda': 0.127826826748361, 'max_bin': 130}. Best is trial 0 with value: 0.1467475774758256.\n",
      "[I 2025-11-30 15:35:31,513] Trial 7 finished with value: 0.1487928758715413 and parameters: {'learning_rate': 0.14716889172020353, 'n_estimators': 579, 'max_depth': 5, 'min_child_weight': 5.7731849953048275, 'subsample': 0.6654742298123172, 'colsample_bytree': 0.5853922720939813, 'colsample_bylevel': 0.7784406553929717, 'gamma': 6.75503470273056, 'reg_alpha': 8.893414995853494, 'reg_lambda': 0.40973889827859783, 'max_bin': 435}. Best is trial 0 with value: 0.1467475774758256.\n",
      "[I 2025-11-30 15:36:07,287] Trial 8 finished with value: 0.14915653617174632 and parameters: {'learning_rate': 0.12160845251051618, 'n_estimators': 461, 'max_depth': 5, 'min_child_weight': 12.580713688950318, 'subsample': 0.8598961336059461, 'colsample_bytree': 0.7454101338703711, 'colsample_bylevel': 0.7284575936619813, 'gamma': 2.8490715848654133, 'reg_alpha': 0.9213397497003383, 'reg_lambda': 1.811769290805607, 'max_bin': 360}. Best is trial 0 with value: 0.1467475774758256.\n",
      "[I 2025-11-30 15:36:46,749] Trial 9 finished with value: 0.14417424514953284 and parameters: {'learning_rate': 0.17341743791122685, 'n_estimators': 442, 'max_depth': 6, 'min_child_weight': 3.0135497176665456, 'subsample': 0.796713795236012, 'colsample_bytree': 0.47816186254050763, 'colsample_bylevel': 0.9499624938754749, 'gamma': 2.2240451913437402, 'reg_alpha': 1.0457564766675789, 'reg_lambda': 0.17925959300619201, 'max_bin': 434}. Best is trial 9 with value: 0.14417424514953284.\n",
      "[I 2025-11-30 15:37:15,641] Trial 10 finished with value: 0.15560001741290452 and parameters: {'learning_rate': 0.1991702761788266, 'n_estimators': 509, 'max_depth': 3, 'min_child_weight': 3.0748222927071542, 'subsample': 0.8441405339356629, 'colsample_bytree': 0.330452239625568, 'colsample_bylevel': 0.5051689388685672, 'gamma': 1.1914046544317662, 'reg_alpha': 0.31119155039517493, 'reg_lambda': 0.8348318695019028, 'max_bin': 505}. Best is trial 9 with value: 0.14417424514953284.\n",
      "[I 2025-11-30 15:38:46,465] Trial 11 finished with value: 0.14844174115146824 and parameters: {'learning_rate': 0.03003268039261962, 'n_estimators': 873, 'max_depth': 7, 'min_child_weight': 79.63894000039262, 'subsample': 0.8067909221407599, 'colsample_bytree': 0.6747886937525983, 'colsample_bylevel': 0.9950312760695981, 'gamma': 1.2223914537592466, 'reg_alpha': 0.102583873176086, 'reg_lambda': 0.9976995156490318, 'max_bin': 437}. Best is trial 9 with value: 0.14417424514953284.\n",
      "[I 2025-11-30 15:39:59,410] Trial 12 finished with value: 0.15070570671294442 and parameters: {'learning_rate': 0.03585839925635551, 'n_estimators': 769, 'max_depth': 6, 'min_child_weight': 26.849167599018823, 'subsample': 0.8011415026107042, 'colsample_bytree': 0.4213049109187706, 'colsample_bylevel': 0.9993766694987325, 'gamma': 3.3329864104931213, 'reg_alpha': 0.33392626798669356, 'reg_lambda': 4.776049868212337, 'max_bin': 418}. Best is trial 9 with value: 0.14417424514953284.\n",
      "[I 2025-11-30 15:41:02,726] Trial 13 finished with value: 0.14587507281226417 and parameters: {'learning_rate': 0.06372547380633029, 'n_estimators': 610, 'max_depth': 7, 'min_child_weight': 3.6534647319099567, 'subsample': 0.8989911073117854, 'colsample_bytree': 0.5706080326708041, 'colsample_bylevel': 0.8842767273557359, 'gamma': 2.4108466891009326, 'reg_alpha': 1.8174559022842591, 'reg_lambda': 17.565441173112905, 'max_bin': 510}. Best is trial 9 with value: 0.14417424514953284.\n",
      "[I 2025-11-30 15:41:52,948] Trial 14 finished with value: 0.14881999855379935 and parameters: {'learning_rate': 0.06607395204687398, 'n_estimators': 556, 'max_depth': 6, 'min_child_weight': 3.0305734248886256, 'subsample': 0.8914354816758723, 'colsample_bytree': 0.642736640648736, 'colsample_bylevel': 0.8620877350948939, 'gamma': 2.1001679625321206, 'reg_alpha': 1.6664527799711515, 'reg_lambda': 16.993516413191898, 'max_bin': 510}. Best is trial 9 with value: 0.14417424514953284.\n",
      "[I 2025-11-30 15:42:23,884] Trial 15 finished with value: 0.14505549573473225 and parameters: {'learning_rate': 0.18684454308515194, 'n_estimators': 446, 'max_depth': 7, 'min_child_weight': 4.484432321559379, 'subsample': 0.8965609382018112, 'colsample_bytree': 0.558006444800929, 'colsample_bylevel': 0.8588273346976508, 'gamma': 4.82026611965132, 'reg_alpha': 1.6203618398420678, 'reg_lambda': 2.6180875138918847, 'max_bin': 479}. Best is trial 9 with value: 0.14417424514953284.\n",
      "[I 2025-11-30 15:42:53,200] Trial 16 finished with value: 0.1466170731843128 and parameters: {'learning_rate': 0.19528763542975847, 'n_estimators': 429, 'max_depth': 6, 'min_child_weight': 4.890108688301029, 'subsample': 0.8003351948686254, 'colsample_bytree': 0.40267642818237737, 'colsample_bylevel': 0.8154178281463307, 'gamma': 4.996250408301882, 'reg_alpha': 0.9262462616208536, 'reg_lambda': 2.5635642363603184, 'max_bin': 208}. Best is trial 9 with value: 0.14417424514953284.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-30 15:43:24,762] Trial 17 finished with value: 0.14582657720041295 and parameters: {'learning_rate': 0.16151245095428227, 'n_estimators': 493, 'max_depth': 7, 'min_child_weight': 10.425680565011305, 'subsample': 0.841098092708128, 'colsample_bytree': 0.696042531489659, 'colsample_bylevel': 0.9066740394939384, 'gamma': 6.714749037235559, 'reg_alpha': 0.5048116274121143, 'reg_lambda': 0.5495457944568578, 'max_bin': 467}. Best is trial 9 with value: 0.14417424514953284.\n",
      "[I 2025-11-30 15:43:57,502] Trial 18 finished with value: 0.1508722041261947 and parameters: {'learning_rate': 0.1111563335371216, 'n_estimators': 403, 'max_depth': 5, 'min_child_weight': 8.665613693324678, 'subsample': 0.7739391476866416, 'colsample_bytree': 0.5392889491273387, 'colsample_bylevel': 0.8082938759898792, 'gamma': 4.213061419335467, 'reg_alpha': 2.697923784235733, 'reg_lambda': 4.794017065286828, 'max_bin': 376}. Best is trial 9 with value: 0.14417424514953284.\n",
      "[I 2025-11-30 15:44:28,511] Trial 19 finished with value: 0.14740561491355278 and parameters: {'learning_rate': 0.16455568648119986, 'n_estimators': 525, 'max_depth': 6, 'min_child_weight': 4.336968429372322, 'subsample': 0.8682177778029132, 'colsample_bytree': 0.7972456991571544, 'colsample_bylevel': 0.9500379838525127, 'gamma': 7.768723198465302, 'reg_alpha': 1.4642905208643717, 'reg_lambda': 2.385391798682543, 'max_bin': 394}. Best is trial 9 with value: 0.14417424514953284.\n",
      "[I 2025-11-30 15:45:09,296] Trial 20 finished with value: 0.14789044401074547 and parameters: {'learning_rate': 0.07932393437150555, 'n_estimators': 382, 'max_depth': 7, 'min_child_weight': 4.462164459555573, 'subsample': 0.8216702135048494, 'colsample_bytree': 0.5501591434089022, 'colsample_bylevel': 0.6645193431716854, 'gamma': 5.838230323550936, 'reg_alpha': 0.6022570296664518, 'reg_lambda': 7.140721899011685, 'max_bin': 467}. Best is trial 9 with value: 0.14417424514953284.\n",
      "[I 2025-11-30 15:45:38,294] Trial 21 finished with value: 0.1468443569476597 and parameters: {'learning_rate': 0.16358594143365202, 'n_estimators': 479, 'max_depth': 7, 'min_child_weight': 9.430385739481553, 'subsample': 0.8452348332485135, 'colsample_bytree': 0.6536611454634166, 'colsample_bylevel': 0.8968925656611932, 'gamma': 7.984013327942092, 'reg_alpha': 0.49960901159588095, 'reg_lambda': 0.5818069071503954, 'max_bin': 469}. Best is trial 9 with value: 0.14417424514953284.\n",
      "[I 2025-11-30 15:46:13,848] Trial 22 finished with value: 0.14519316965587556 and parameters: {'learning_rate': 0.15403883856408668, 'n_estimators': 620, 'max_depth': 7, 'min_child_weight': 8.25006693532437, 'subsample': 0.8716312019901987, 'colsample_bytree': 0.7123238034522414, 'colsample_bylevel': 0.9252751768151798, 'gamma': 6.305710740492433, 'reg_alpha': 1.0945166827023305, 'reg_lambda': 0.18900766395580132, 'max_bin': 472}. Best is trial 9 with value: 0.14417424514953284.\n",
      "[I 2025-11-30 15:46:51,832] Trial 23 finished with value: 0.1469119926858258 and parameters: {'learning_rate': 0.1358873544240492, 'n_estimators': 628, 'max_depth': 6, 'min_child_weight': 7.141673334751197, 'subsample': 0.8776331456889817, 'colsample_bytree': 0.7239637713025692, 'colsample_bylevel': 0.8350716862264979, 'gamma': 5.970708569222811, 'reg_alpha': 1.1799797565758414, 'reg_lambda': 0.19340968306720505, 'max_bin': 469}. Best is trial 9 with value: 0.14417424514953284.\n",
      "[I 2025-11-30 15:47:35,304] Trial 24 finished with value: 0.14226851980169183 and parameters: {'learning_rate': 0.19998570170455632, 'n_estimators': 687, 'max_depth': 7, 'min_child_weight': 5.441759731202355, 'subsample': 0.780218351263169, 'colsample_bytree': 0.769739120815676, 'colsample_bylevel': 0.9553771482874794, 'gamma': 4.345945751363333, 'reg_alpha': 2.572047028510029, 'reg_lambda': 0.1560558876938432, 'max_bin': 446}. Best is trial 24 with value: 0.14226851980169183.\n",
      "[I 2025-11-30 15:48:17,223] Trial 25 finished with value: 0.14404446996045742 and parameters: {'learning_rate': 0.18102375810934274, 'n_estimators': 721, 'max_depth': 6, 'min_child_weight': 5.287570104243582, 'subsample': 0.7760813784292281, 'colsample_bytree': 0.7580446704759017, 'colsample_bylevel': 0.9666274570437638, 'gamma': 4.524999889957082, 'reg_alpha': 3.486794599475887, 'reg_lambda': 0.3476521472847291, 'max_bin': 253}. Best is trial 24 with value: 0.14226851980169183.\n",
      "[I 2025-11-30 15:49:08,130] Trial 26 finished with value: 0.14463577621242915 and parameters: {'learning_rate': 0.11276313669021001, 'n_estimators': 700, 'max_depth': 6, 'min_child_weight': 5.5625247710586025, 'subsample': 0.7637246106002574, 'colsample_bytree': 0.7992661948555662, 'colsample_bylevel': 0.9720754264040178, 'gamma': 4.013777582801896, 'reg_alpha': 8.679486835581743, 'reg_lambda': 0.3620864092524684, 'max_bin': 249}. Best is trial 24 with value: 0.14226851980169183.\n",
      "[I 2025-11-30 15:49:59,851] Trial 27 finished with value: 0.14391453818036146 and parameters: {'learning_rate': 0.17699405199946697, 'n_estimators': 760, 'max_depth': 5, 'min_child_weight': 3.3123018491583367, 'subsample': 0.707613924612524, 'colsample_bytree': 0.7529667754055636, 'colsample_bylevel': 0.9531418691945732, 'gamma': 1.8813405475079565, 'reg_alpha': 2.4218177999530646, 'reg_lambda': 0.15257044219379426, 'max_bin': 232}. Best is trial 24 with value: 0.14226851980169183.\n",
      "[I 2025-11-30 15:50:50,919] Trial 28 finished with value: 0.14959290212213242 and parameters: {'learning_rate': 0.1423177184056492, 'n_estimators': 802, 'max_depth': 4, 'min_child_weight': 3.7612476481422172, 'subsample': 0.7055892462296307, 'colsample_bytree': 0.7561558456155075, 'colsample_bylevel': 0.5805350008214879, 'gamma': 4.9007778604221, 'reg_alpha': 3.0442935733108247, 'reg_lambda': 0.10014157694936784, 'max_bin': 207}. Best is trial 24 with value: 0.14226851980169183.\n",
      "[I 2025-11-30 15:51:45,459] Trial 29 finished with value: 0.14436538359389423 and parameters: {'learning_rate': 0.18372295978577985, 'n_estimators': 758, 'max_depth': 5, 'min_child_weight': 5.735926602262038, 'subsample': 0.638718813020776, 'colsample_bytree': 0.7579782467236196, 'colsample_bylevel': 0.9507397983017745, 'gamma': 3.6819310360369752, 'reg_alpha': 5.006687204246357, 'reg_lambda': 0.32272029197540336, 'max_bin': 242}. Best is trial 24 with value: 0.14226851980169183.\n",
      "[I 2025-11-30 15:52:23,882] Trial 30 finished with value: 0.1544542639525935 and parameters: {'learning_rate': 0.09850047484075608, 'n_estimators': 833, 'max_depth': 3, 'min_child_weight': 11.995411444382793, 'subsample': 0.7758050658874656, 'colsample_bytree': 0.7748736742184231, 'colsample_bylevel': 0.9819997178080891, 'gamma': 2.041646658974225, 'reg_alpha': 2.7275275947021678, 'reg_lambda': 0.5385469432862781, 'max_bin': 163}. Best is trial 24 with value: 0.14226851980169183.\n",
      "[I 2025-11-30 15:53:18,096] Trial 31 finished with value: 0.1443332310901153 and parameters: {'learning_rate': 0.17093588161848902, 'n_estimators': 729, 'max_depth': 5, 'min_child_weight': 3.508393755956698, 'subsample': 0.7883938321652539, 'colsample_bytree': 0.7326331852011733, 'colsample_bylevel': 0.9507784112410531, 'gamma': 1.6686689298484043, 'reg_alpha': 6.512706139496984, 'reg_lambda': 0.15729383968555125, 'max_bin': 261}. Best is trial 24 with value: 0.14226851980169183.\n",
      "[I 2025-11-30 15:53:59,266] Trial 32 finished with value: 0.1485108227674649 and parameters: {'learning_rate': 0.17683565230672152, 'n_estimators': 664, 'max_depth': 4, 'min_child_weight': 3.919749961411503, 'subsample': 0.7249998154824325, 'colsample_bytree': 0.6820505357213256, 'colsample_bylevel': 0.9322809320412629, 'gamma': 2.9065600021073283, 'reg_alpha': 2.4174381779792697, 'reg_lambda': 0.150296663180747, 'max_bin': 209}. Best is trial 24 with value: 0.14226851980169183.\n",
      "[I 2025-11-30 15:54:56,790] Trial 33 finished with value: 0.1441760304935475 and parameters: {'learning_rate': 0.12290427335335836, 'n_estimators': 649, 'max_depth': 6, 'min_child_weight': 3.006807042656662, 'subsample': 0.7508214855871813, 'colsample_bytree': 0.4682293687680229, 'colsample_bylevel': 0.8956283673233655, 'gamma': 2.4157287920191726, 'reg_alpha': 3.9671267946205737, 'reg_lambda': 0.21463852503743133, 'max_bin': 323}. Best is trial 24 with value: 0.14226851980169183.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-30 15:55:48,789] Trial 34 finished with value: 0.15151271516047285 and parameters: {'learning_rate': 0.05065836511838557, 'n_estimators': 739, 'max_depth': 5, 'min_child_weight': 5.223510217491775, 'subsample': 0.7009924343209415, 'colsample_bytree': 0.518571402168277, 'colsample_bylevel': 0.9620793900202779, 'gamma': 1.0086056391641087, 'reg_alpha': 3.325912893674448, 'reg_lambda': 0.2663895963895437, 'max_bin': 176}. Best is trial 24 with value: 0.14226851980169183.\n",
      "[I 2025-11-30 15:56:38,296] Trial 35 finished with value: 0.14240346618349997 and parameters: {'learning_rate': 0.19896752419515884, 'n_estimators': 806, 'max_depth': 6, 'min_child_weight': 5.9230560467311495, 'subsample': 0.819620487342055, 'colsample_bytree': 0.7797485486956824, 'colsample_bylevel': 0.9183041186795611, 'gamma': 3.529210390923677, 'reg_alpha': 0.7334023513482986, 'reg_lambda': 0.10037944481909725, 'max_bin': 271}. Best is trial 24 with value: 0.14226851980169183.\n",
      "[I 2025-11-30 15:57:26,621] Trial 36 finished with value: 0.148139756529855 and parameters: {'learning_rate': 0.14748872724649548, 'n_estimators': 813, 'max_depth': 4, 'min_child_weight': 6.704876649530548, 'subsample': 0.8230915024542469, 'colsample_bytree': 0.7728402224361339, 'colsample_bylevel': 0.9224784678184832, 'gamma': 3.40469847057562, 'reg_alpha': 0.7731381652944463, 'reg_lambda': 0.1008023334603786, 'max_bin': 283}. Best is trial 24 with value: 0.14226851980169183.\n",
      "[I 2025-11-30 15:58:08,493] Trial 37 finished with value: 0.1463082040767939 and parameters: {'learning_rate': 0.19799439883122982, 'n_estimators': 840, 'max_depth': 5, 'min_child_weight': 18.470244314172348, 'subsample': 0.7283393715130582, 'colsample_bytree': 0.7076112886732379, 'colsample_bylevel': 0.882830328875935, 'gamma': 5.465149737345784, 'reg_alpha': 6.252314024265882, 'reg_lambda': 0.12924570144503592, 'max_bin': 231}. Best is trial 24 with value: 0.14226851980169183.\n",
      "[I 2025-11-30 15:59:01,419] Trial 38 finished with value: 0.14418728737875927 and parameters: {'learning_rate': 0.13171552279065968, 'n_estimators': 695, 'max_depth': 6, 'min_child_weight': 7.451742271634028, 'subsample': 0.6657266855588996, 'colsample_bytree': 0.6298130294968538, 'colsample_bylevel': 0.981161290488461, 'gamma': 4.564339642626642, 'reg_alpha': 2.161475649785798, 'reg_lambda': 0.2703292649924791, 'max_bin': 267}. Best is trial 24 with value: 0.14226851980169183.\n",
      "[I 2025-11-30 15:59:58,144] Trial 39 finished with value: 0.1440845699731133 and parameters: {'learning_rate': 0.151150257494459, 'n_estimators': 868, 'max_depth': 6, 'min_child_weight': 40.98744358847312, 'subsample': 0.7688586487006284, 'colsample_bytree': 0.6054647694529058, 'colsample_bylevel': 0.7863891567780761, 'gamma': 3.8396547119593496, 'reg_alpha': 3.8630601070469184, 'reg_lambda': 0.4347231390183199, 'max_bin': 319}. Best is trial 24 with value: 0.14226851980169183.\n",
      "[I 2025-11-30 16:00:40,251] Trial 40 finished with value: 0.1505090562238176 and parameters: {'learning_rate': 0.09471381393765126, 'n_estimators': 785, 'max_depth': 5, 'min_child_weight': 17.206212982428447, 'subsample': 0.8259015031163446, 'colsample_bytree': 0.6657864023699993, 'colsample_bylevel': 0.9197405780993528, 'gamma': 9.824372550480412, 'reg_alpha': 1.3320805890176781, 'reg_lambda': 0.13392789473780123, 'max_bin': 300}. Best is trial 24 with value: 0.14226851980169183.\n",
      "[I 2025-11-30 16:01:39,439] Trial 41 finished with value: 0.14386895159434726 and parameters: {'learning_rate': 0.15294512328562895, 'n_estimators': 890, 'max_depth': 6, 'min_child_weight': 40.026435442058094, 'subsample': 0.7632291526359506, 'colsample_bytree': 0.6098956035036901, 'colsample_bylevel': 0.7802586567782669, 'gamma': 3.7691476283952854, 'reg_alpha': 3.825217737975478, 'reg_lambda': 0.3889318111557673, 'max_bin': 330}. Best is trial 24 with value: 0.14226851980169183.\n",
      "[I 2025-11-30 16:02:24,359] Trial 42 finished with value: 0.14538298203180314 and parameters: {'learning_rate': 0.18189976080858528, 'n_estimators': 892, 'max_depth': 6, 'min_child_weight': 44.758634741789635, 'subsample': 0.7515285535976862, 'colsample_bytree': 0.776909525177524, 'colsample_bylevel': 0.6691656400719461, 'gamma': 5.281109104934461, 'reg_alpha': 4.237122438730891, 'reg_lambda': 0.7271606278199281, 'max_bin': 225}. Best is trial 24 with value: 0.14226851980169183.\n",
      "[I 2025-11-30 16:03:23,385] Trial 43 finished with value: 0.1448610194489715 and parameters: {'learning_rate': 0.17722077672569117, 'n_estimators': 844, 'max_depth': 5, 'min_child_weight': 61.846431065433386, 'subsample': 0.7841613046919476, 'colsample_bytree': 0.7409353388440907, 'colsample_bylevel': 0.7342898040287378, 'gamma': 3.280287610464661, 'reg_alpha': 6.32622409598383, 'reg_lambda': 0.22363973032861353, 'max_bin': 338}. Best is trial 24 with value: 0.14226851980169183.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Keep your existing scaled data & keys:\n",
    "# X_train_scaled, X_test_scaled, y_train, y_test, train_key, test_key\n",
    "\n",
    "# Train/validation split (same pattern as your snippet)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train_scaled, y_train, test_size=0.3, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "n_classes = len(np.unique(y_train))\n",
    "is_binary = (n_classes == 2)\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        # ---- Objective & eval metric ----\n",
    "        \"objective\": \"binary:logistic\" if is_binary else \"multi:softprob\",\n",
    "        \"num_class\": None if is_binary else n_classes,\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"eval_metric\": \"logloss\" if is_binary else \"mlogloss\",\n",
    "\n",
    "        # ---- Learning rate & trees ----\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.03, 0.2, log=True),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 300, 900),\n",
    "\n",
    "        # ---- Tree complexity ----\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 3.0, 80.0, log=True),\n",
    "\n",
    "        # ---- Row & feature subsampling ----\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 0.9),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.3, 0.8),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.5, 1.0),\n",
    "\n",
    "        # ---- Regularization ----\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 1.0, 10.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.1, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.1, 20.0, log=True),\n",
    "\n",
    "        # ---- Histogram granularity ----\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 128, 512),\n",
    "\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        # tip: for heavy class imbalance (binary), consider\n",
    "        # \"scale_pos_weight\": (neg/pos)  you can add as a suggested_float/int\n",
    "    }\n",
    "\n",
    "    # Fit\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_tr, y_tr)\n",
    "\n",
    "    # Validate via log loss (works for binary & multiclass)\n",
    "    proba = model.predict_proba(X_val)\n",
    "    return log_loss(y_val, proba, labels=np.unique(y_train))\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aaed5b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(\"Best LogLoss:\", study.best_value)\n",
    "# print(\"Best params:\", study.best_params)\n",
    "\n",
    "# # Retrain on full training set with best params\n",
    "# best_params = {\n",
    "#     **study.best_params,\n",
    "#     \"objective\": \"binary:logistic\",\n",
    "#     \"num_class\": None,\n",
    "#     \"tree_method\": \"hist\",\n",
    "#     \"eval_metric\": \"logloss\",\n",
    "#     \"random_state\": 42,\n",
    "#     \"n_jobs\": -1,\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "best_params = {\n",
    "    'learning_rate': 0.19998570170455632, 'n_estimators': 687, 'max_depth': 7, 'min_child_weight': 5.441759731202355,\n",
    "    'subsample': 0.780218351263169, 'colsample_bytree': 0.769739120815676, 'colsample_bylevel': 0.9553771482874794,\n",
    "    'gamma': 4.345945751363333, 'reg_alpha': 2.572047028510029, 'reg_lambda': 0.1560558876938432, 'max_bin': 446,\n",
    "\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"num_class\": None,\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1,\n",
    "}\n",
    "\n",
    "\n",
    "# Save best params\n",
    "with open(f\"best_cls_params_{datetime.strftime(datetime.now(), '%Y%m%d%H%M')}_.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5a953ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRAIN METRICS ===\n",
      "Accuracy: 0.9451733638007861\n",
      "Precision (macro): 0.8847743103479765\n",
      "Recall (macro): 0.8058966485004759\n",
      "F1 (macro): 0.8394148595180828\n",
      "ROC-AUC: 0.9634052138657881\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97   6652479\n",
      "           1       0.81      0.63      0.71    790655\n",
      "\n",
      "    accuracy                           0.95   7443134\n",
      "   macro avg       0.88      0.81      0.84   7443134\n",
      "weighted avg       0.94      0.95      0.94   7443134\n",
      "\n",
      "\n",
      "=== TEST METRICS ===\n",
      "Accuracy: 0.9441257839158723\n",
      "Precision (macro): 0.8814815337721205\n",
      "Recall (macro): 0.8030803288973039\n",
      "F1 (macro): 0.836371669218396\n",
      "ROC-AUC: 0.9601165050716871\n",
      "Confusion matrix:\n",
      " [[2800146   50750]\n",
      " [ 127484  211535]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97   2850896\n",
      "           1       0.81      0.62      0.70    339019\n",
      "\n",
      "    accuracy                           0.94   3189915\n",
      "   macro avg       0.88      0.80      0.84   3189915\n",
      "weighted avg       0.94      0.94      0.94   3189915\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2537162/3102008149.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_key['pred_class'] = y_tr_pred\n",
      "/tmp/ipykernel_2537162/3102008149.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_key['pred_proba'] = y_tr_proba[:, 1]\n",
      "/tmp/ipykernel_2537162/3102008149.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_key['pred_class'] = y_te_pred\n",
      "/tmp/ipykernel_2537162/3102008149.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_key['pred_proba'] = y_te_proba[:, 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "best_model = XGBClassifier(**best_params)\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --- Predictions ---\n",
    "y_tr_pred = best_model.predict(X_train_scaled)\n",
    "y_te_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Probabilities (for AUC/thresholding)\n",
    "y_tr_proba = best_model.predict_proba(X_train_scaled)\n",
    "y_te_proba = best_model.predict_proba(X_test_scaled)\n",
    "\n",
    "# --- Metrics (train) ---\n",
    "print(\"\\n=== TRAIN METRICS ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_tr_pred))\n",
    "print(\"Precision (macro):\", precision_score(y_train, y_tr_pred, average=\"macro\", zero_division=0))\n",
    "print(\"Recall (macro):\", recall_score(y_train, y_tr_pred, average=\"macro\", zero_division=0))\n",
    "print(\"F1 (macro):\", f1_score(y_train, y_tr_pred, average=\"macro\", zero_division=0))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_train, y_tr_proba[:, 1]))\n",
    "\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_train, y_tr_pred, zero_division=0))\n",
    "\n",
    "# --- Metrics (test) ---\n",
    "print(\"\\n=== TEST METRICS ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_te_pred))\n",
    "print(\"Precision (macro):\", precision_score(y_test, y_te_pred, average=\"macro\", zero_division=0))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_te_pred, average=\"macro\", zero_division=0))\n",
    "print(\"F1 (macro):\", f1_score(y_test, y_te_pred, average=\"macro\", zero_division=0))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_te_proba[:, 1]))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_te_pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_te_pred, zero_division=0))\n",
    "\n",
    "\n",
    "train_key['pred_class'] = y_tr_pred\n",
    "train_key['pred_proba'] = y_tr_proba[:, 1]\n",
    "test_key['pred_class'] = y_te_pred\n",
    "test_key['pred_proba'] = y_te_proba[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0c7cdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_xgb = (train_key,test_key, best_model, best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da588977",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89abfdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_op_xgb.pkl', 'wb') as f:\n",
    "    pickle.dump(data_dict_xgb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a96aa59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_op_xgb = pd.concat([\n",
    "    data_dict_xgb[0],\n",
    "    data_dict_xgb[1]\n",
    "          ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d330f4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>substitute_id</th>\n",
       "      <th>GMM_cluster_id</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>pred_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9335088</th>\n",
       "      <td>154565</td>\n",
       "      <td>1367172</td>\n",
       "      <td>2962</td>\n",
       "      <td>22089</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0.049592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9944958</th>\n",
       "      <td>151073</td>\n",
       "      <td>2857952</td>\n",
       "      <td>46045</td>\n",
       "      <td>27606</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704721</th>\n",
       "      <td>150638</td>\n",
       "      <td>790551</td>\n",
       "      <td>45401</td>\n",
       "      <td>15468</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492248</th>\n",
       "      <td>101433</td>\n",
       "      <td>1387828</td>\n",
       "      <td>33731</td>\n",
       "      <td>4799</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.597095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4682778</th>\n",
       "      <td>164774</td>\n",
       "      <td>1971432</td>\n",
       "      <td>25890</td>\n",
       "      <td>30446</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234489</th>\n",
       "      <td>105158</td>\n",
       "      <td>2360613</td>\n",
       "      <td>13284</td>\n",
       "      <td>24037</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4304572</th>\n",
       "      <td>73645</td>\n",
       "      <td>1757942</td>\n",
       "      <td>16290</td>\n",
       "      <td>49612</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10081351</th>\n",
       "      <td>122230</td>\n",
       "      <td>2005721</td>\n",
       "      <td>28476</td>\n",
       "      <td>4256</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6550634</th>\n",
       "      <td>109541</td>\n",
       "      <td>3306192</td>\n",
       "      <td>13176</td>\n",
       "      <td>37646</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.554273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6423388</th>\n",
       "      <td>15466</td>\n",
       "      <td>3179874</td>\n",
       "      <td>24852</td>\n",
       "      <td>25388</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7443134 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  order_id  product_id  substitute_id  GMM_cluster_id  \\\n",
       "9335088    154565   1367172        2962          22089              63   \n",
       "9944958    151073   2857952       46045          27606              75   \n",
       "2704721    150638    790551       45401          15468              16   \n",
       "2492248    101433   1387828       33731           4799              15   \n",
       "4682778    164774   1971432       25890          30446              35   \n",
       "...           ...       ...         ...            ...             ...   \n",
       "2234489    105158   2360613       13284          24037              14   \n",
       "4304572     73645   1757942       16290          49612              32   \n",
       "10081351   122230   2005721       28476           4256              79   \n",
       "6550634    109541   3306192       13176          37646              40   \n",
       "6423388     15466   3179874       24852          25388              40   \n",
       "\n",
       "          pred_class  pred_proba  \n",
       "9335088            0    0.049592  \n",
       "9944958            0    0.000428  \n",
       "2704721            0    0.001799  \n",
       "2492248            1    0.597095  \n",
       "4682778            0    0.001871  \n",
       "...              ...         ...  \n",
       "2234489            0    0.009275  \n",
       "4304572            0    0.002715  \n",
       "10081351           0    0.003210  \n",
       "6550634            1    0.554273  \n",
       "6423388            0    0.000076  \n",
       "\n",
       "[7443134 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict_xgb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f76414b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad155023",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_op_xgb.rename({'pred_proba' : 'pred_xgb'}, axis = 1).to_csv('../data/preds_train_test_op_xgb.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5759d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7ee36f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a622deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b479a3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
