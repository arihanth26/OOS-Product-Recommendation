{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d589d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bucket features from: artifacts/features/X_bucket_pca.npy\n",
      "Loading bucket index mapping from: artifacts/features/bucket_index.parquet\n",
      "Loading P0->P1 mapping from: artifacts/buckets/product_to_bucket.parquet\n",
      "Mapping neighbor P1 buckets to P0 product IDs...\n",
      "Loading P0->P1 mapping from: artifacts/buckets/product_to_bucket.parquet\n",
      "Mapping neighbor P1 buckets to P0 product IDs...\n",
      "\n",
      "Successfully calculated and saved 35429 rows of closest neighbors to ../data/processed/product_substitution_neighbors_p0.csv\n",
      "✓ All neighbors are from the SAME GMM cluster as the source product\n",
      "\n",
      "Columns:\n",
      "  - Source_P0_Product_ID (P0), Source_P1_Bucket_ID (P1), GMM_Cluster_ID (P2)\n",
      "  - Closest_1..10_P0_Product_ID (neighbor P0 IDs within same cluster)\n",
      "  - Distance_1..10 (Euclidean distance in PCA feature space)\n",
      "\n",
      "Result Head:\n",
      "   Source_P0_Product_ID  Source_P1_Bucket_ID  GMM_Cluster_ID  \\\n",
      "0                  2343                  844               0   \n",
      "1                 10917                  945               0   \n",
      "2                 49680                  986               0   \n",
      "3                 30699                  992               0   \n",
      "4                 41532                  993               0   \n",
      "\n",
      "   Closest_1_P0_Product_ID  Distance_1  Closest_2_P0_Product_ID  Distance_2  \\\n",
      "0                    32364    0.037477                    12330    0.043428   \n",
      "1                    23818    0.246748                    17409    0.251234   \n",
      "2                    31702    0.268671                     9493    0.274905   \n",
      "3                    17680    0.127962                     6860    0.129530   \n",
      "4                    23160    0.107830                    12147    0.147638   \n",
      "\n",
      "   Closest_3_P0_Product_ID  Distance_3  Closest_4_P0_Product_ID  ...  \\\n",
      "0                    27212    0.046686                    39347  ...   \n",
      "1                    14044    0.281849                    39296  ...   \n",
      "2                    30959    0.388281                     4370  ...   \n",
      "3                    34022    0.146884                    18495  ...   \n",
      "4                    45960    0.180733                     6872  ...   \n",
      "\n",
      "   Closest_6_P0_Product_ID  Distance_6  Closest_7_P0_Product_ID  Distance_7  \\\n",
      "0                    20026    0.100203                     9171    0.128460   \n",
      "1                    41423    1.249410                    48876    1.338341   \n",
      "2                     8935    1.177387                    23343    1.196376   \n",
      "3                    45028    0.150404                    26582    0.150423   \n",
      "4                    15853    1.050989                     5556    1.404736   \n",
      "\n",
      "   Closest_8_P0_Product_ID  Distance_8  Closest_9_P0_Product_ID  Distance_9  \\\n",
      "0                    23177    0.168683                    23791    0.222634   \n",
      "1                    28414    1.348863                    23974    1.383918   \n",
      "2                    23974    1.197076                    41423    1.232138   \n",
      "3                    41998    0.151096                    37794    0.158974   \n",
      "4                     3121    1.406959                    35626    1.407229   \n",
      "\n",
      "   Closest_10_P0_Product_ID  Distance_10  \n",
      "0                     28328     0.362063  \n",
      "1                     12781     1.385591  \n",
      "2                     15853     1.296778  \n",
      "3                     35435     0.168730  \n",
      "4                     29892     1.409434  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "Successfully calculated and saved 35429 rows of closest neighbors to ../data/processed/product_substitution_neighbors_p0.csv\n",
      "✓ All neighbors are from the SAME GMM cluster as the source product\n",
      "\n",
      "Columns:\n",
      "  - Source_P0_Product_ID (P0), Source_P1_Bucket_ID (P1), GMM_Cluster_ID (P2)\n",
      "  - Closest_1..10_P0_Product_ID (neighbor P0 IDs within same cluster)\n",
      "  - Distance_1..10 (Euclidean distance in PCA feature space)\n",
      "\n",
      "Result Head:\n",
      "   Source_P0_Product_ID  Source_P1_Bucket_ID  GMM_Cluster_ID  \\\n",
      "0                  2343                  844               0   \n",
      "1                 10917                  945               0   \n",
      "2                 49680                  986               0   \n",
      "3                 30699                  992               0   \n",
      "4                 41532                  993               0   \n",
      "\n",
      "   Closest_1_P0_Product_ID  Distance_1  Closest_2_P0_Product_ID  Distance_2  \\\n",
      "0                    32364    0.037477                    12330    0.043428   \n",
      "1                    23818    0.246748                    17409    0.251234   \n",
      "2                    31702    0.268671                     9493    0.274905   \n",
      "3                    17680    0.127962                     6860    0.129530   \n",
      "4                    23160    0.107830                    12147    0.147638   \n",
      "\n",
      "   Closest_3_P0_Product_ID  Distance_3  Closest_4_P0_Product_ID  ...  \\\n",
      "0                    27212    0.046686                    39347  ...   \n",
      "1                    14044    0.281849                    39296  ...   \n",
      "2                    30959    0.388281                     4370  ...   \n",
      "3                    34022    0.146884                    18495  ...   \n",
      "4                    45960    0.180733                     6872  ...   \n",
      "\n",
      "   Closest_6_P0_Product_ID  Distance_6  Closest_7_P0_Product_ID  Distance_7  \\\n",
      "0                    20026    0.100203                     9171    0.128460   \n",
      "1                    41423    1.249410                    48876    1.338341   \n",
      "2                     8935    1.177387                    23343    1.196376   \n",
      "3                    45028    0.150404                    26582    0.150423   \n",
      "4                    15853    1.050989                     5556    1.404736   \n",
      "\n",
      "   Closest_8_P0_Product_ID  Distance_8  Closest_9_P0_Product_ID  Distance_9  \\\n",
      "0                    23177    0.168683                    23791    0.222634   \n",
      "1                    28414    1.348863                    23974    1.383918   \n",
      "2                    23974    1.197076                    41423    1.232138   \n",
      "3                    41998    0.151096                    37794    0.158974   \n",
      "4                     3121    1.406959                    35626    1.407229   \n",
      "\n",
      "   Closest_10_P0_Product_ID  Distance_10  \n",
      "0                     28328     0.362063  \n",
      "1                     12781     1.385591  \n",
      "2                     15853     1.296778  \n",
      "3                     35435     0.168730  \n",
      "4                     29892     1.409434  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# The GMM k-NN function remains the same (keeps feature column prefix 'feature_').\n",
    "def find_k_nearest_neighbors_within_cluster(df_features_and_clusters, k=10):\n",
    "    \"\"\"\n",
    "    Finds the k closest products (P1 buckets) to every product within their assigned GMM cluster (P2).\n",
    "    Expects df_features_and_clusters to contain 'P1_Bucket_ID', 'GMM_Cluster_ID' and feature_* columns.\n",
    "    \"\"\"\n",
    "    feature_cols = [col for col in df_features_and_clusters.columns if col.startswith('feature_')]\n",
    "\n",
    "    if not feature_cols:\n",
    "        raise ValueError(\"Feature columns (e.g., 'feature_1' to 'feature_96') not found.\")\n",
    "\n",
    "    all_results = []\n",
    "    for cluster_id, cluster_data in df_features_and_clusters.groupby('GMM_Cluster_ID'):\n",
    "        X = cluster_data[feature_cols].values\n",
    "        p1_ids = cluster_data['P1_Bucket_ID'].values\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        if n_samples <= k:\n",
    "            # skip clusters that don't have enough members\n",
    "            continue\n",
    "\n",
    "        nn_model = NearestNeighbors(n_neighbors=k + 1, metric='euclidean', algorithm='auto')\n",
    "        nn_model.fit(X)\n",
    "        distances, indices = nn_model.kneighbors(X, return_distance=True)\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            source_p1 = p1_ids[i]\n",
    "            neighbor_indices = indices[i, 1:]  # skip self\n",
    "            neighbor_distances = distances[i, 1:]\n",
    "            closest_p1_ids = p1_ids[neighbor_indices]\n",
    "\n",
    "            result = {'Source_P1_Bucket_ID': source_p1, 'GMM_Cluster_ID': cluster_id}\n",
    "            for j in range(k):\n",
    "                result[f'Closest_{j+1}_P1_ID'] = closest_p1_ids[j]\n",
    "                result[f'Distance_{j+1}'] = float(neighbor_distances[j])\n",
    "            all_results.append(result)\n",
    "\n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "# --- Example Usage: load real artifacts when available ---\n",
    "try:\n",
    "    # 1. Load Cluster Data (P1/P2)\n",
    "    cluster_csv_candidates = [\"../data/processed/gmm_cluster_product_details_for_analysis.csv\", \"data/processed/gmm_cluster_product_details_for_analysis.csv\"]\n",
    "    cluster_path = None\n",
    "    for p in cluster_csv_candidates:\n",
    "        if os.path.exists(p):\n",
    "            cluster_path = p\n",
    "            break\n",
    "    if cluster_path is None:\n",
    "        raise FileNotFoundError(\"Could not find gmm_cluster_product_details_for_analysis.csv in expected locations.\")\n",
    "    cluster_df = pd.read_csv(cluster_path)\n",
    "    cluster_df = cluster_df[['P1_Bucket_ID', 'GMM_Cluster_ID']].drop_duplicates()\n",
    "\n",
    "    # 2. Load bucket-level features (prefer X_bucket_pca.npy) and bucket index mapping\n",
    "    feature_npy_candidates = [\"artifacts/features/X_bucket_pca.npy\", \"artifacts/features/X_product_pca.npy\", \"../notebooks/artifacts/features/X_bucket_pca.npy\", \"notebooks/artifacts/features/X_bucket_pca.npy\"]\n",
    "    bucket_index_candidates = [\"artifacts/features/bucket_index.parquet\", \"artifacts/features/bucket_index.csv\", \"artifacts/buckets/bucket_index.parquet\", \"notebooks/artifacts/features/bucket_index.parquet\"]\n",
    "\n",
    "    feature_npy_path = None\n",
    "    for p in feature_npy_candidates:\n",
    "        if os.path.exists(p):\n",
    "            feature_npy_path = p\n",
    "            break\n",
    "\n",
    "    bucket_index_path = None\n",
    "    for p in bucket_index_candidates:\n",
    "        if os.path.exists(p):\n",
    "            bucket_index_path = p\n",
    "            break\n",
    "\n",
    "    if feature_npy_path is None or bucket_index_path is None:\n",
    "        # fallback: try to load precomputed notebook artifacts relative to this notebook\n",
    "        alt_feature = 'artifacts/features/X_bucket_pca.npy'\n",
    "        alt_index = 'artifacts/features/bucket_index.parquet'\n",
    "        if os.path.exists(alt_feature) and os.path.exists(alt_index):\n",
    "            feature_npy_path = alt_feature\n",
    "            bucket_index_path = alt_index\n",
    "\n",
    "    if feature_npy_path is None or bucket_index_path is None:\n",
    "        raise FileNotFoundError(\"Could not find bucket features (X_bucket_pca.npy) or bucket_index.parquet.\")\n",
    "\n",
    "    print(f\"Loading bucket features from: {feature_npy_path}\")\n",
    "    X_buckets = np.load(feature_npy_path)\n",
    "\n",
    "    print(f\"Loading bucket index mapping from: {bucket_index_path}\")\n",
    "    # bucket_index is expected to have a column linking each row of X_buckets to a P1_Bucket_ID\n",
    "    if bucket_index_path.endswith('.parquet'):\n",
    "        bucket_index = pd.read_parquet(bucket_index_path)\n",
    "    else:\n",
    "        bucket_index = pd.read_csv(bucket_index_path)\n",
    "\n",
    "    # Try to find P1 id column in bucket_index\n",
    "    if 'P1_Bucket_ID' in bucket_index.columns:\n",
    "        p1_col = 'P1_Bucket_ID'\n",
    "    elif 'P1' in bucket_index.columns:\n",
    "        p1_col = 'P1'\n",
    "    else:\n",
    "        # try index\n",
    "        if bucket_index.index.is_unique:\n",
    "            bucket_index = bucket_index.reset_index()\n",
    "            p1_col = bucket_index.columns[0]\n",
    "        else:\n",
    "            raise ValueError(\"Could not infer P1_Bucket_ID column from bucket_index file.\")\n",
    "\n",
    "    p1_list = bucket_index[p1_col].values\n",
    "    if len(p1_list) != X_buckets.shape[0]:\n",
    "        raise ValueError(\"Length mismatch: bucket features rows do not match bucket_index rows.\")\n",
    "\n",
    "    # Create feature dataframe\n",
    "    feature_cols = [f'feature_{i}' for i in range(1, X_buckets.shape[1] + 1)]\n",
    "    df_features = pd.DataFrame(X_buckets, columns=feature_cols)\n",
    "    df_features['P1_Bucket_ID'] = p1_list\n",
    "\n",
    "    # 3. Create the required input for the k-NN function\n",
    "    df_features_and_clusters = pd.merge(cluster_df, df_features, on='P1_Bucket_ID', how='inner')\n",
    "\n",
    "    # 4. Run the k-NN calculation (P1 to P1)\n",
    "    df_closest_neighbors = find_k_nearest_neighbors_within_cluster(df_features_and_clusters, k=10)\n",
    "\n",
    "    # 5. Load / infer P0 -> P1 mapping (try several artifact locations)\n",
    "    p0p1_candidates = [\n",
    "        'artifacts/buckets/product_to_bucket.parquet',\n",
    "        'artifacts/features/meta_product.parquet',\n",
    "        'artifacts/graph/nodes_p1_buckets.csv',\n",
    "        '../notebooks/artifacts/buckets/product_to_bucket.parquet',\n",
    "        '../notebooks/artifacts/features/meta_product.parquet',\n",
    "        '../data/processed/products_with_prices_ingredients_nutrition.csv'\n",
    "    ]\n",
    "    p0p1_path = None\n",
    "    for p in p0p1_candidates:\n",
    "        if os.path.exists(p):\n",
    "            p0p1_path = p\n",
    "            break\n",
    "\n",
    "    if p0p1_path is None:\n",
    "        # as a last resort, try to build a non-redundant mapping from the products CSV if present\n",
    "        raise FileNotFoundError(\"Could not find a P0->P1 mapping file. Looked for product_to_bucket.parquet or meta_product.parquet.\")\n",
    "\n",
    "    print(f\"Loading P0->P1 mapping from: {p0p1_path}\")\n",
    "    if p0p1_path.endswith('.parquet'):\n",
    "        df_map = pd.read_parquet(p0p1_path)\n",
    "    else:\n",
    "        df_map = pd.read_csv(p0p1_path)\n",
    "\n",
    "    # Normalize columns to 'product_id' and 'P1_Bucket_ID' if possible\n",
    "    possible_pid = [c for c in df_map.columns if 'product' in c.lower()][:1]\n",
    "    possible_p1 = [c for c in df_map.columns if 'p1' in c.lower() or 'bucket' in c.lower()][:1]\n",
    "    if not possible_pid or not possible_p1:\n",
    "        # try common names\n",
    "        if 'product_id' in df_map.columns and 'P1_Bucket_ID' in df_map.columns:\n",
    "            df_p0_p1_map = df_map[['product_id', 'P1_Bucket_ID']].copy()\n",
    "        else:\n",
    "            raise ValueError(\"Could not find product_id and P1 mapping columns in the P0->P1 file.\")\n",
    "    else:\n",
    "        df_p0_p1_map = df_map[[possible_pid[0], possible_p1[0]]].copy()\n",
    "        df_p0_p1_map.columns = ['product_id', 'P1_Bucket_ID']\n",
    "\n",
    "    # 6. Join the P0 IDs to the k-NN results for SOURCE product\n",
    "    df_final = pd.merge(df_closest_neighbors, df_p0_p1_map, left_on='Source_P1_Bucket_ID', right_on='P1_Bucket_ID', how='left')\n",
    "    df_final = df_final.rename(columns={'product_id': 'Source_P0_Product_ID'})\n",
    "    df_final = df_final.drop(columns=['P1_Bucket_ID'])\n",
    "\n",
    "    # 7. Map neighbor P1 buckets to P0 product IDs\n",
    "    print(\"Mapping neighbor P1 buckets to P0 product IDs...\")\n",
    "    p1_to_p0 = df_p0_p1_map.set_index('P1_Bucket_ID')['product_id'].to_dict()\n",
    "    \n",
    "    for j in range(1, 11):\n",
    "        p1_col = f'Closest_{j}_P1_ID'\n",
    "        p0_col = f'Closest_{j}_P0_Product_ID'\n",
    "        if p1_col in df_final.columns:\n",
    "            df_final[p0_col] = df_final[p1_col].map(p1_to_p0)\n",
    "            # Drop the P1 column since we only want P0 in final output\n",
    "            df_final = df_final.drop(columns=[p1_col])\n",
    "\n",
    "    # Reorder columns: Source (P0, P1, P2), then neighbors (P0, Distance)\n",
    "    base_cols = ['Source_P0_Product_ID', 'Source_P1_Bucket_ID', 'GMM_Cluster_ID']\n",
    "    neighbor_cols = []\n",
    "    for j in range(1, 11):\n",
    "        neighbor_cols.extend([f'Closest_{j}_P0_Product_ID', f'Distance_{j}'])\n",
    "    \n",
    "    remaining_cols = [c for c in df_final.columns if c not in base_cols and c not in neighbor_cols]\n",
    "    df_final = df_final[base_cols + neighbor_cols + remaining_cols]\n",
    "\n",
    "    # 8. Output the results to CSV\n",
    "    output_filename = '../data/processed/product_substitution_neighbors_p0.csv'\n",
    "    os.makedirs(os.path.dirname(output_filename), exist_ok=True)\n",
    "    df_final.to_csv(output_filename, index=False)\n",
    "\n",
    "    print(f\"\\nSuccessfully calculated and saved {len(df_final)} rows of closest neighbors to {output_filename}\")\n",
    "    print(f\"✓ All neighbors are from the SAME GMM cluster as the source product\")\n",
    "    print(f\"\\nColumns:\")\n",
    "    print(f\"  - Source_P0_Product_ID (P0), Source_P1_Bucket_ID (P1), GMM_Cluster_ID (P2)\")\n",
    "    print(f\"  - Closest_1..10_P0_Product_ID (neighbor P0 IDs within same cluster)\")\n",
    "    print(f\"  - Distance_1..10 (Euclidean distance in PCA feature space)\")\n",
    "    print(\"\\nResult Head:\")\n",
    "    try:\n",
    "        print(df_final.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "    except Exception:\n",
    "        print(df_final.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"\\nAn error occurred during execution. Ensure bucket feature artifacts and the P0->P1 mapping file are available.\")\n",
    "    print(f\"Error details: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
